{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 09. Exercise 03\n",
                "# Ensembles"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Запуск контейнера с нужными версиями\n",
                "\n",
                "docker run -d \\\n",
                "  --platform linux/amd64 \\\n",
                "  -p 8888:8888 \\\n",
                "  -v $(pwd):/home/jovyan/work \\\n",
                "  --name sklearn \\\n",
                "  jupyter/scipy-notebook:python-3.8 \\\n",
                "  bash -c \"pip install scikit-learn==0.23.1 tqdm==4.46.1 && start-notebook.sh --NotebookApp.token=''\"\n",
                "\n",
                "#### и выбираем правильный kernel в vscode на localhost (который отдает докер)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 193,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Python версия: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n",
                        "[GCC 10.3.0]\n",
                        "scikit-learn версия: 0.23.1\n",
                        "pandas версия: 1.5.0\n",
                        "numpy версия: 1.23.3\n",
                        "tqdm версия: 4.64.1\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "print(\"Python версия:\", sys.version)\n",
                "\n",
                "import sklearn\n",
                "print(\"scikit-learn версия:\", sklearn.__version__)\n",
                "\n",
                "import pandas as pd\n",
                "print(\"pandas версия:\", pd.__version__)\n",
                "\n",
                "import numpy as np\n",
                "print(\"numpy версия:\", np.__version__)\n",
                "\n",
                "import tqdm\n",
                "print(\"tqdm версия:\", tqdm.__version__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 194,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
                "import joblib\n",
                "import json\n",
                "import itertools"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Create the same dataframe as in the previous exercise.\n",
                "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 195,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Размерность данных: (1686, 43)\n",
                        "Колонки в файле: ['numTrials', 'hour', 'uid_user_0', 'uid_user_1', 'uid_user_10', 'uid_user_11', 'uid_user_12', 'uid_user_13', 'uid_user_14', 'uid_user_15', 'uid_user_16', 'uid_user_17', 'uid_user_18', 'uid_user_19', 'uid_user_2', 'uid_user_20', 'uid_user_21', 'uid_user_22', 'uid_user_23', 'uid_user_24', 'uid_user_25', 'uid_user_26', 'uid_user_27', 'uid_user_28', 'uid_user_29', 'uid_user_3', 'uid_user_30', 'uid_user_31', 'uid_user_4', 'uid_user_6', 'uid_user_7', 'uid_user_8', 'labname_code_rvw', 'labname_lab02', 'labname_lab03', 'labname_lab03s', 'labname_lab05s', 'labname_laba04', 'labname_laba04s', 'labname_laba05', 'labname_laba06', 'labname_laba06s', 'labname_project1']\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv('work/src/data/day-of-week-not-scaled.csv')\n",
                "print(f\"Размерность данных: {df.shape}\")\n",
                "print(f\"Колонки в файле: {df.columns.tolist()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 196,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Новая размерность: (1686, 44)\n",
                        "Финальные колонки: ['numTrials', 'hour', 'uid_user_0', 'uid_user_1', 'uid_user_10', 'uid_user_11', 'uid_user_12', 'uid_user_13', 'uid_user_14', 'uid_user_15', 'uid_user_16', 'uid_user_17', 'uid_user_18', 'uid_user_19', 'uid_user_2', 'uid_user_20', 'uid_user_21', 'uid_user_22', 'uid_user_23', 'uid_user_24', 'uid_user_25', 'uid_user_26', 'uid_user_27', 'uid_user_28', 'uid_user_29', 'uid_user_3', 'uid_user_30', 'uid_user_31', 'uid_user_4', 'uid_user_6', 'uid_user_7', 'uid_user_8', 'labname_code_rvw', 'labname_lab02', 'labname_lab03', 'labname_lab03s', 'labname_lab05s', 'labname_laba04', 'labname_laba04s', 'labname_laba05', 'labname_laba06', 'labname_laba06s', 'labname_project1', 'dayofweek']\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>numTrials</th>\n",
                            "      <th>hour</th>\n",
                            "      <th>uid_user_0</th>\n",
                            "      <th>uid_user_1</th>\n",
                            "      <th>uid_user_10</th>\n",
                            "      <th>uid_user_11</th>\n",
                            "      <th>uid_user_12</th>\n",
                            "      <th>uid_user_13</th>\n",
                            "      <th>uid_user_14</th>\n",
                            "      <th>uid_user_15</th>\n",
                            "      <th>...</th>\n",
                            "      <th>labname_lab03</th>\n",
                            "      <th>labname_lab03s</th>\n",
                            "      <th>labname_lab05s</th>\n",
                            "      <th>labname_laba04</th>\n",
                            "      <th>labname_laba04s</th>\n",
                            "      <th>labname_laba05</th>\n",
                            "      <th>labname_laba06</th>\n",
                            "      <th>labname_laba06s</th>\n",
                            "      <th>labname_project1</th>\n",
                            "      <th>dayofweek</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 44 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   numTrials  hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
                            "0          1     5         0.0         0.0          0.0          0.0   \n",
                            "1          2     5         0.0         0.0          0.0          0.0   \n",
                            "2          3     5         0.0         0.0          0.0          0.0   \n",
                            "3          4     5         0.0         0.0          0.0          0.0   \n",
                            "4          5     5         0.0         0.0          0.0          0.0   \n",
                            "\n",
                            "   uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
                            "0          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "1          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "2          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "3          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "4          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "\n",
                            "   labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
                            "0             0.0             0.0             0.0              0.0   \n",
                            "1             0.0             0.0             0.0              0.0   \n",
                            "2             0.0             0.0             0.0              0.0   \n",
                            "3             0.0             0.0             0.0              0.0   \n",
                            "4             0.0             0.0             0.0              0.0   \n",
                            "\n",
                            "   labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
                            "0             0.0             0.0              0.0               1.0   \n",
                            "1             0.0             0.0              0.0               1.0   \n",
                            "2             0.0             0.0              0.0               1.0   \n",
                            "3             0.0             0.0              0.0               1.0   \n",
                            "4             0.0             0.0              0.0               1.0   \n",
                            "\n",
                            "   dayofweek  \n",
                            "0          4  \n",
                            "1          4  \n",
                            "2          4  \n",
                            "3          4  \n",
                            "4          4  \n",
                            "\n",
                            "[5 rows x 44 columns]"
                        ]
                    },
                    "execution_count": 196,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_target = pd.read_csv('work/src/data/dayofweek.csv')\n",
                "\n",
                "df['dayofweek'] = df_target['dayofweek']\n",
                "\n",
                "print(f\"Новая размерность: {df.shape}\")\n",
                "print(\"Финальные колонки:\", df.columns.tolist())\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 197,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Распределение целевой переменной:\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0    136\n",
                            "1    274\n",
                            "2    149\n",
                            "3    396\n",
                            "4    104\n",
                            "5    271\n",
                            "6    356\n",
                            "Name: dayofweek, dtype: int64"
                        ]
                    },
                    "execution_count": 197,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "print(\"Распределение целевой переменной:\")\n",
                "df['dayofweek'].value_counts().sort_index()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 198,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Первое разделение:\n",
                        "Размерность тренировочного набора: (1348, 43)\n",
                        "Размерность тестового набора: (338, 43)\n"
                    ]
                }
            ],
            "source": [
                "X = df.drop('dayofweek', axis=1)\n",
                "y = df['dayofweek']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=0.2, \n",
                "    random_state=21, \n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(\"Первое разделение:\")\n",
                "print(\"Размерность тренировочного набора:\", X_train.shape)\n",
                "print(\"Размерность тестового набора:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 199,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Второе разделение:\n",
                        "Финальная размерность тренировочного набора: (1078, 43)\n",
                        "Размерность валидационного набора: (270, 43)\n",
                        "Размерность тестового набора: (338, 43)\n"
                    ]
                }
            ],
            "source": [
                "X_train, X_valid, y_train, y_valid = train_test_split(\n",
                "    X_train, y_train, \n",
                "    test_size=0.2,\n",
                "    random_state=21, \n",
                "    stratify=y_train\n",
                ")\n",
                "\n",
                "print(\"Второе разделение:\")\n",
                "print(\"Финальная размерность тренировочного набора:\", X_train.shape)\n",
                "print(\"Размерность валидационного набора:\", X_valid.shape)\n",
                "print(\"Размерность тестового набора:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 200,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Распределение в тренировочной выборке:\n",
                        "0     87\n",
                        "1    175\n",
                        "2     95\n",
                        "3    253\n",
                        "4     66\n",
                        "5    174\n",
                        "6    228\n",
                        "Name: dayofweek, dtype: int64\n",
                        "Распределение в валидационной выборке:\n",
                        "0    22\n",
                        "1    44\n",
                        "2    24\n",
                        "3    63\n",
                        "4    17\n",
                        "5    43\n",
                        "6    57\n",
                        "Name: dayofweek, dtype: int64\n",
                        "Распределение в тестовой выборке:\n",
                        "0    27\n",
                        "1    55\n",
                        "2    30\n",
                        "3    80\n",
                        "4    21\n",
                        "5    54\n",
                        "6    71\n",
                        "Name: dayofweek, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"Распределение в тренировочной выборке:\")\n",
                "print(y_train.value_counts().sort_index())\n",
                "print(\"Распределение в валидационной выборке:\")\n",
                "print(y_valid.value_counts().sort_index())\n",
                "print(\"Распределение в тестовой выборке:\")\n",
                "print(y_test.value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Individual classifiers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
                "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
                "3. The result of each cell of the section should look like this:\n",
                "\n",
                "```\n",
                "accuracy is 0.87778\n",
                "precision is 0.88162\n",
                "recall is 0.87778\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 201,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Обучение индивидуальных классификаторов с лучшими параметрами из ex01 ===\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Обучение индивидуальных классификаторов с лучшими параметрами из ex01 ===\\n\")\n",
                "\n",
                "svm_ex01_params = {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', \"probability\": True, \"random_state\": 21}\n",
                "svm_best = SVC(**svm_ex01_params)\n",
                "\n",
                "dt_best = DecisionTreeClassifier(\n",
                "    max_depth=21,\n",
                "    criterion='gini',\n",
                "    class_weight='balanced',\n",
                "    random_state=21\n",
                ")\n",
                "\n",
                "rf_best = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=24,\n",
                "    criterion='entropy',\n",
                "    class_weight='balanced',\n",
                "    random_state=21\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 202,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Обучение SVM...\n",
                        "accuracy is 0.87778\n",
                        "precision is 0.88162\n",
                        "recall is 0.87778\n",
                        "CPU times: user 862 ms, sys: 6.36 ms, total: 868 ms\n",
                        "Wall time: 775 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"Обучение SVM...\")\n",
                "svm_best.fit(X_train, y_train)\n",
                "\n",
                "svm_pred = svm_best.predict(X_valid)\n",
                "svm_accuracy = accuracy_score(y_valid, svm_pred)\n",
                "svm_precision = precision_score(y_valid, svm_pred, average='weighted')\n",
                "svm_recall = recall_score(y_valid, svm_pred, average='weighted')\n",
                "\n",
                "print(f\"accuracy is {svm_accuracy:.5f}\")\n",
                "print(f\"precision is {svm_precision:.5f}\")\n",
                "print(f\"recall is {svm_recall:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 203,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Обучение Decision Tree...\n",
                        "accuracy is 0.86667\n",
                        "precision is 0.87170\n",
                        "recall is 0.86667\n",
                        "CPU times: user 32.9 ms, sys: 9.05 ms, total: 42 ms\n",
                        "Wall time: 28 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"Обучение Decision Tree...\")\n",
                "dt_best.fit(X_train, y_train)\n",
                "\n",
                "dt_pred = dt_best.predict(X_valid)\n",
                "dt_accuracy = accuracy_score(y_valid, dt_pred)\n",
                "dt_precision = precision_score(y_valid, dt_pred, average='weighted')\n",
                "dt_recall = recall_score(y_valid, dt_pred, average='weighted')\n",
                "\n",
                "print(f\"accuracy is {dt_accuracy:.5f}\")\n",
                "print(f\"precision is {dt_precision:.5f}\")\n",
                "print(f\"recall is {dt_recall:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 204,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Обучение Random Forest...\n",
                        "accuracy is 0.89630\n",
                        "precision is 0.89698\n",
                        "recall is 0.89630\n",
                        "CPU times: user 248 ms, sys: 5.02 ms, total: 253 ms\n",
                        "Wall time: 251 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"Обучение Random Forest...\")\n",
                "rf_best.fit(X_train, y_train)\n",
                "\n",
                "rf_pred = rf_best.predict(X_valid)\n",
                "rf_accuracy = accuracy_score(y_valid, rf_pred)\n",
                "rf_precision = precision_score(y_valid, rf_pred, average='weighted')\n",
                "rf_recall = recall_score(y_valid, rf_pred, average='weighted')\n",
                "\n",
                "print(f\"accuracy is {rf_accuracy:.5f}\")\n",
                "print(f\"precision is {rf_precision:.5f}\")\n",
                "print(f\"recall is {rf_recall:.5f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Voting classifiers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
                "2. Play with the other parameteres.\n",
                "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 205,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Обучение стандартного Voting Classifier...\n",
                        "accuracy is 0.90000\n",
                        "precision is 0.89993\n",
                        "recall is 0.90000\n",
                        "CPU times: user 956 ms, sys: 7.09 ms, total: 963 ms\n",
                        "Wall time: 960 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "voting_default = VotingClassifier(\n",
                "    estimators=[\n",
                "        ('svm', svm_best),\n",
                "        ('dt', dt_best),\n",
                "        ('rf', rf_best)\n",
                "    ],\n",
                "    voting='hard'\n",
                ")\n",
                "\n",
                "print(\"Обучение стандартного Voting Classifier...\")\n",
                "voting_default.fit(X_train, y_train)\n",
                "\n",
                "voting_default_pred = voting_default.predict(X_valid)\n",
                "voting_default_accuracy = accuracy_score(y_valid, voting_default_pred)\n",
                "voting_default_precision = precision_score(y_valid, voting_default_pred, average='weighted')\n",
                "voting_default_recall = recall_score(y_valid, voting_default_pred, average='weighted')\n",
                "\n",
                "print(f\"accuracy is {voting_default_accuracy:.5f}\")\n",
                "print(f\"precision is {voting_default_precision:.5f}\")\n",
                "print(f\"recall is {voting_default_recall:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 206,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Эксперименты с различными параметрами голосования ===\n",
                        "\n",
                        "Всего экспериментов для запуска: 430\n",
                        "Прогресс: 1/430\n",
                        "Прогресс: 51/430\n",
                        "Прогресс: 101/430\n",
                        "Прогресс: 151/430\n",
                        "Прогресс: 201/430\n",
                        "Прогресс: 251/430\n",
                        "Прогресс: 301/430\n",
                        "Прогресс: 351/430\n",
                        "Прогресс: 401/430\n",
                        "\n",
                        "Топ-10 лучших комбинаций голосования:\n",
                        "1. soft_w102: accuracy=0.92593, precision=0.92943, weights=[1, 0, 2]\n",
                        "2. soft_w204: accuracy=0.92593, precision=0.92943, weights=[2, 0, 4]\n",
                        "3. soft_w305: accuracy=0.91481, precision=0.91748, weights=[3, 0, 5]\n",
                        "4. soft_w414: accuracy=0.91111, precision=0.91288, weights=[4, 1, 4]\n",
                        "5. soft_w103: accuracy=0.91111, precision=0.91155, weights=[1, 0, 3]\n",
                        "6. soft_w205: accuracy=0.91111, precision=0.91155, weights=[2, 0, 5]\n",
                        "7. soft_w415: accuracy=0.91111, precision=0.91144, weights=[4, 1, 5]\n",
                        "8. soft_w511: accuracy=0.90741, precision=0.91149, weights=[5, 1, 1]\n",
                        "9. soft_w512: accuracy=0.90741, precision=0.91149, weights=[5, 1, 2]\n",
                        "10. soft_w413: accuracy=0.90741, precision=0.91099, weights=[4, 1, 3]\n",
                        "CPU times: user 5min 11s, sys: 689 ms, total: 5min 12s\n",
                        "Wall time: 5min 12s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Эксперименты с различными параметрами голосования ===\\n\")\n",
                "\n",
                "voting_experiments = []\n",
                "\n",
                "voting_types = ['hard', 'soft']\n",
                "weight_range = range(0, 6)\n",
                "\n",
                "experiments = []\n",
                "\n",
                "for voting_type in voting_types:\n",
                "    for w1, w2, w3 in itertools.product(weight_range, repeat=3):\n",
                "        if w1 == 0 and w2 == 0 and w3 == 0:\n",
                "            continue\n",
                "        \n",
                "        if (w1 + w2 + w3) <= 15:\n",
                "            experiments.append({\n",
                "                'voting': voting_type, \n",
                "                'weights': [w1, w2, w3], \n",
                "                'name': f'{voting_type}_w{w1}{w2}{w3}'\n",
                "            })\n",
                "\n",
                "print(f\"Всего экспериментов для запуска: {len(experiments)}\")\n",
                "\n",
                "for i, exp in enumerate(experiments):\n",
                "    if i % 50 == 0:\n",
                "        print(f\"Прогресс: {i+1}/{len(experiments)}\")\n",
                "    \n",
                "    voting_clf = VotingClassifier(\n",
                "        estimators=[\n",
                "            ('svm', svm_best),\n",
                "            ('dt', dt_best),\n",
                "            ('rf', rf_best)\n",
                "        ],\n",
                "        voting=exp['voting'],\n",
                "        weights=exp['weights']\n",
                "    )\n",
                "    \n",
                "    voting_clf.fit(X_train, y_train)\n",
                "    pred = voting_clf.predict(X_valid)\n",
                "    \n",
                "    accuracy = accuracy_score(y_valid, pred)\n",
                "    precision = precision_score(y_valid, pred, average='weighted')\n",
                "    recall = recall_score(y_valid, pred, average='weighted')\n",
                "    \n",
                "    voting_experiments.append({\n",
                "        'name': exp['name'],\n",
                "        'voting': exp['voting'],\n",
                "        'weights': exp['weights'],\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'model': voting_clf\n",
                "    })\n",
                "\n",
                "top_10 = sorted(voting_experiments, key=lambda x: (x['accuracy'], x['precision']), reverse=True)[:10]\n",
                "print(\"\\nТоп-10 лучших комбинаций голосования:\")\n",
                "for i, result in enumerate(top_10, 1):\n",
                "    print(f\"{i}. {result['name']}: accuracy={result['accuracy']:.5f}, precision={result['precision']:.5f}, weights={result['weights']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 219,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== А теперь для чеклиста без нулей ===\n",
                        "\n",
                        "Всего экспериментов для запуска: 128\n",
                        "Прогресс: 1/128\n",
                        "Прогресс: 51/128\n",
                        "Прогресс: 101/128\n",
                        "Завершены все 128 экспериментов!\n",
                        "\n",
                        "Топ-10 лучших комбинаций голосования:\n",
                        "1. soft_w414: accuracy=0.91111, precision=0.91288, weights=[4, 1, 4]\n",
                        "2. soft_w413: accuracy=0.90741, precision=0.91099, weights=[4, 1, 3]\n",
                        "3. soft_w411: accuracy=0.90741, precision=0.91026, weights=[4, 1, 1]\n",
                        "4. soft_w412: accuracy=0.90741, precision=0.91026, weights=[4, 1, 2]\n",
                        "5. soft_w324: accuracy=0.90741, precision=0.91012, weights=[3, 2, 4]\n",
                        "6. hard_w232: accuracy=0.90741, precision=0.90773, weights=[2, 3, 2]\n",
                        "7. hard_w243: accuracy=0.90741, precision=0.90773, weights=[2, 4, 3]\n",
                        "8. hard_w342: accuracy=0.90741, precision=0.90773, weights=[3, 4, 2]\n",
                        "9. hard_w343: accuracy=0.90741, precision=0.90773, weights=[3, 4, 3]\n",
                        "10. soft_w322: accuracy=0.90370, precision=0.90610, weights=[3, 2, 2]\n",
                        "CPU times: user 1min 46s, sys: 207 ms, total: 1min 46s\n",
                        "Wall time: 1min 46s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== А теперь для чеклиста без нулей ===\\n\")\n",
                "\n",
                "voting_experiments = []\n",
                "\n",
                "voting_types = ['hard', 'soft']\n",
                "weight_range = range(1, 5)\n",
                "\n",
                "experiments = []\n",
                "\n",
                "for voting_type in voting_types:\n",
                "    for w1, w2, w3 in itertools.product(weight_range, repeat=3):\n",
                "        if w1 == 0 and w2 == 0 and w3 == 0:\n",
                "            continue\n",
                "        \n",
                "        experiments.append({\n",
                "            'voting': voting_type, \n",
                "            'weights': [w1, w2, w3], \n",
                "            'name': f'{voting_type}_w{w1}{w2}{w3}'\n",
                "        })\n",
                "\n",
                "print(f\"Всего экспериментов для запуска: {len(experiments)}\")\n",
                "\n",
                "for i, exp in enumerate(experiments):\n",
                "    if i % 50 == 0:\n",
                "        print(f\"Прогресс: {i+1}/{len(experiments)}\")\n",
                "    \n",
                "    voting_clf = VotingClassifier(\n",
                "        estimators=[\n",
                "            ('svm', svm_best),\n",
                "            ('dt', dt_best),\n",
                "            ('rf', rf_best)\n",
                "        ],\n",
                "        voting=exp['voting'],\n",
                "        weights=exp['weights']\n",
                "    )\n",
                "    \n",
                "    voting_clf.fit(X_train, y_train)\n",
                "    pred = voting_clf.predict(X_valid)\n",
                "    \n",
                "    accuracy = accuracy_score(y_valid, pred)\n",
                "    precision = precision_score(y_valid, pred, average='weighted')\n",
                "    recall = recall_score(y_valid, pred, average='weighted')\n",
                "    \n",
                "    voting_experiments.append({\n",
                "        'name': exp['name'],\n",
                "        'voting': exp['voting'],\n",
                "        'weights': exp['weights'],\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'model': voting_clf\n",
                "    })\n",
                "\n",
                "print(f\"Завершены все {len(experiments)} экспериментов!\")\n",
                "\n",
                "top_10 = sorted(voting_experiments, key=lambda x: (x['accuracy'], x['precision']), reverse=True)[:10]\n",
                "print(\"\\nТоп-10 лучших комбинаций голосования:\")\n",
                "for i, result in enumerate(top_10, 1):\n",
                "    print(f\"{i}. {result['name']}: accuracy={result['accuracy']:.5f}, precision={result['precision']:.5f}, weights={result['weights']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 208,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Лучший voting classifier: soft_w414\n",
                        "Точность на валидации: 0.91111\n",
                        "Precision на валидации: 0.91288\n",
                        "\n",
                        "Лучший Voting Classifier - результаты на тестовом наборе:\n",
                        "accuracy is 0.90533\n",
                        "precision is 0.90881\n",
                        "recall is 0.90533\n"
                    ]
                }
            ],
            "source": [
                "voting_experiments.append({\n",
                "    'name': 'hard_equal',\n",
                "    'accuracy': voting_default_accuracy,\n",
                "    'precision': voting_default_precision,\n",
                "    'recall': voting_default_recall,\n",
                "    'model': voting_default\n",
                "})\n",
                "\n",
                "best_voting = max(voting_experiments, key=lambda x: (x['accuracy'], x['precision']))\n",
                "print(f\"Лучший voting classifier: {best_voting['name']}\")\n",
                "print(f\"Точность на валидации: {best_voting['accuracy']:.5f}\")\n",
                "print(f\"Precision на валидации: {best_voting['precision']:.5f}\")\n",
                "\n",
                "best_voting_model = best_voting['model']\n",
                "voting_test_pred = best_voting_model.predict(X_test)\n",
                "voting_test_accuracy = accuracy_score(y_test, voting_test_pred)\n",
                "voting_test_precision = precision_score(y_test, voting_test_pred, average='weighted')\n",
                "voting_test_recall = recall_score(y_test, voting_test_pred, average='weighted')\n",
                "\n",
                "print(f\"\\nЛучший Voting Classifier - результаты на тестовом наборе:\")\n",
                "print(f\"accuracy is {voting_test_accuracy:.5f}\")\n",
                "print(f\"precision is {voting_test_precision:.5f}\")\n",
                "print(f\"recall is {voting_test_recall:.5f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Bagging classifiers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
                "2. Play with the other parameters.\n",
                "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 209,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Шаг 1: Различные n_estimators ===\n",
                        "\n",
                        "Тестируем n_estimators=5\n",
                        "accuracy is 0.70370\n",
                        "precision is 0.73089\n",
                        "recall is 0.70370\n",
                        "\n",
                        "Тестируем n_estimators=10\n",
                        "accuracy is 0.77778\n",
                        "precision is 0.81225\n",
                        "recall is 0.77778\n",
                        "\n",
                        "Тестируем n_estimators=25\n",
                        "accuracy is 0.82222\n",
                        "precision is 0.84354\n",
                        "recall is 0.82222\n",
                        "\n",
                        "Тестируем n_estimators=50\n",
                        "accuracy is 0.83333\n",
                        "precision is 0.85141\n",
                        "recall is 0.83333\n",
                        "\n",
                        "Лучший n_estimators: 50\n",
                        "CPU times: user 21.4 s, sys: 11.6 ms, total: 21.4 s\n",
                        "Wall time: 21.4 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Шаг 1: Различные n_estimators ===\")\n",
                "\n",
                "n_estimators_values = [5, 10, 25, 50]\n",
                "bagging_results = []\n",
                "\n",
                "for n_est in n_estimators_values:\n",
                "    print(f\"\\nТестируем n_estimators={n_est}\")\n",
                "    \n",
                "    bagging_svm = BaggingClassifier(\n",
                "        base_estimator=svm_best,\n",
                "        n_estimators=n_est,\n",
                "        bootstrap_features=True,\n",
                "        random_state=21\n",
                "    )\n",
                "    \n",
                "    bagging_svm.fit(X_train, y_train)\n",
                "    pred = bagging_svm.predict(X_valid)\n",
                "    \n",
                "    accuracy = accuracy_score(y_valid, pred)\n",
                "    precision = precision_score(y_valid, pred, average='weighted')\n",
                "    recall = recall_score(y_valid, pred, average='weighted')\n",
                "    \n",
                "    bagging_results.append({\n",
                "        'n_estimators': n_est,\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'model': bagging_svm\n",
                "    })\n",
                "    \n",
                "    print(f\"accuracy is {accuracy:.5f}\")\n",
                "    print(f\"precision is {precision:.5f}\")\n",
                "    print(f\"recall is {recall:.5f}\")\n",
                "\n",
                "best_n_est_result = max(bagging_results, key=lambda x: (x['accuracy'], x['precision']))\n",
                "print(f\"\\nЛучший n_estimators: {best_n_est_result['n_estimators']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 210,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Шаг 2: Другие параметры ===\n",
                        "\n",
                        "Используем лучший n_estimators=50\n",
                        "\n",
                        "Тестируем max_samples=0.5, max_features=1.0\n",
                        "accuracy is 0.83333\n",
                        "precision is 0.84955\n",
                        "recall is 0.83333\n",
                        "\n",
                        "Тестируем max_samples=0.7, max_features=1.0\n",
                        "accuracy is 0.85556\n",
                        "precision is 0.86899\n",
                        "recall is 0.85556\n",
                        "\n",
                        "Тестируем max_samples=0.8, max_features=1.0\n",
                        "accuracy is 0.87037\n",
                        "precision is 0.88092\n",
                        "recall is 0.87037\n",
                        "\n",
                        "Тестируем max_samples=1.0, max_features=0.5\n",
                        "accuracy is 0.74815\n",
                        "precision is 0.78443\n",
                        "recall is 0.74815\n",
                        "\n",
                        "Тестируем max_samples=1.0, max_features=0.7\n",
                        "accuracy is 0.84444\n",
                        "precision is 0.85762\n",
                        "recall is 0.84444\n",
                        "\n",
                        "Тестируем max_samples=1.0, max_features=0.8\n",
                        "accuracy is 0.87037\n",
                        "precision is 0.87699\n",
                        "recall is 0.87037\n",
                        "\n",
                        "Тестируем max_samples=0.8, max_features=0.8\n",
                        "accuracy is 0.85926\n",
                        "precision is 0.86804\n",
                        "recall is 0.85926\n",
                        "CPU times: user 1min 3s, sys: 40.1 ms, total: 1min 3s\n",
                        "Wall time: 1min 3s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Шаг 2: Другие параметры ===\\n\")\n",
                "\n",
                "best_n_est = best_n_est_result['n_estimators']\n",
                "print(f\"Используем лучший n_estimators={best_n_est}\")\n",
                "\n",
                "other_params = [\n",
                "    {'max_samples': 0.5, 'max_features': 1.0},\n",
                "    {'max_samples': 0.7, 'max_features': 1.0},\n",
                "    {'max_samples': 0.8, 'max_features': 1.0},\n",
                "    {'max_samples': 1.0, 'max_features': 0.5},\n",
                "    {'max_samples': 1.0, 'max_features': 0.7},\n",
                "    {'max_samples': 1.0, 'max_features': 0.8},\n",
                "    {'max_samples': 0.8, 'max_features': 0.8},\n",
                "]\n",
                "\n",
                "for params in other_params:\n",
                "    print(f\"\\nТестируем max_samples={params['max_samples']}, max_features={params['max_features']}\")\n",
                "    \n",
                "    bagging_svm = BaggingClassifier(\n",
                "        base_estimator=svm_best,\n",
                "        n_estimators=50,\n",
                "        max_samples=params['max_samples'],\n",
                "        max_features=params['max_features'],\n",
                "        random_state=21\n",
                "    )\n",
                "    \n",
                "    bagging_svm.fit(X_train, y_train)\n",
                "    pred = bagging_svm.predict(X_valid)\n",
                "    \n",
                "    accuracy = accuracy_score(y_valid, pred)\n",
                "    precision = precision_score(y_valid, pred, average='weighted')\n",
                "    recall = recall_score(y_valid, pred, average='weighted')\n",
                "    \n",
                "    bagging_results.append({\n",
                "        'n_estimators': best_n_est,\n",
                "        'max_samples': params['max_samples'],\n",
                "        'max_features': params['max_features'],\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'model': bagging_svm\n",
                "    })\n",
                "    \n",
                "    print(f\"accuracy is {accuracy:.5f}\")\n",
                "    print(f\"precision is {precision:.5f}\")\n",
                "    print(f\"recall is {recall:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 211,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Лучшие параметры bagging:\n",
                        "n_estimators: 50\n",
                        "max_samples: 0.8\n",
                        "max_features: 1.0\n",
                        "accuracy: 0.8703703703703703\n",
                        "precision: 0.8809178986483951\n",
                        "recall: 0.8703703703703703\n",
                        "\n",
                        "Лучший Bagging - результаты на тестовом наборе:\n",
                        "accuracy is 0.85503\n",
                        "precision is 0.86157\n",
                        "recall is 0.85503\n"
                    ]
                }
            ],
            "source": [
                "final_best_bagging = max(bagging_results, key=lambda x: (x['accuracy'], x['precision']))\n",
                "\n",
                "print(f\"Лучшие параметры bagging:\")\n",
                "for key, value in final_best_bagging.items():\n",
                "    if key != 'model':\n",
                "        print(f\"{key}: {value}\")\n",
                "\n",
                "best_bagging_model = final_best_bagging['model']\n",
                "test_pred = best_bagging_model.predict(X_test)\n",
                "\n",
                "bagging_test_accuracy = accuracy_score(y_test, test_pred)\n",
                "bagging_test_precision = precision_score(y_test, test_pred, average='weighted')\n",
                "bagging_test_recall = recall_score(y_test, test_pred, average='weighted')\n",
                "\n",
                "print(f\"\\nЛучший Bagging - результаты на тестовом наборе:\")\n",
                "print(f\"accuracy is {bagging_test_accuracy:.5f}\")\n",
                "print(f\"precision is {bagging_test_precision:.5f}\")\n",
                "print(f\"recall is {bagging_test_recall:.5f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Stacking classifiers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
                "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
                "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 212,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Эксперименты с Stacking Classifier ===\n",
                        "\n",
                        "\n",
                        "Тестируем n_splits=2, passthrough=True\n",
                        "accuracy is 0.90370\n",
                        "precision is 0.90619\n",
                        "recall is 0.90370\n",
                        "\n",
                        "Тестируем n_splits=2, passthrough=False\n",
                        "accuracy is 0.89630\n",
                        "precision is 0.89678\n",
                        "recall is 0.89630\n",
                        "\n",
                        "Тестируем n_splits=3, passthrough=True\n",
                        "accuracy is 0.90370\n",
                        "precision is 0.90632\n",
                        "recall is 0.90370\n",
                        "\n",
                        "Тестируем n_splits=3, passthrough=False\n",
                        "accuracy is 0.89630\n",
                        "precision is 0.89759\n",
                        "recall is 0.89630\n",
                        "\n",
                        "Тестируем n_splits=4, passthrough=True\n",
                        "accuracy is 0.91111\n",
                        "precision is 0.91327\n",
                        "recall is 0.91111\n",
                        "\n",
                        "Тестируем n_splits=4, passthrough=False\n",
                        "accuracy is 0.90370\n",
                        "precision is 0.90570\n",
                        "recall is 0.90370\n",
                        "\n",
                        "Тестируем n_splits=5, passthrough=True\n",
                        "accuracy is 0.90000\n",
                        "precision is 0.90217\n",
                        "recall is 0.90000\n",
                        "\n",
                        "Тестируем n_splits=5, passthrough=False\n",
                        "accuracy is 0.90000\n",
                        "precision is 0.90056\n",
                        "recall is 0.90000\n",
                        "\n",
                        "Тестируем n_splits=6, passthrough=True\n",
                        "accuracy is 0.90370\n",
                        "precision is 0.90450\n",
                        "recall is 0.90370\n",
                        "\n",
                        "Тестируем n_splits=6, passthrough=False\n",
                        "accuracy is 0.90370\n",
                        "precision is 0.90436\n",
                        "recall is 0.90370\n",
                        "\n",
                        "Тестируем n_splits=7, passthrough=True\n",
                        "accuracy is 0.90370\n",
                        "precision is 0.90640\n",
                        "recall is 0.90370\n",
                        "\n",
                        "Тестируем n_splits=7, passthrough=False\n",
                        "accuracy is 0.90370\n",
                        "precision is 0.90538\n",
                        "recall is 0.90370\n",
                        "CPU times: user 35.7 s, sys: 55.8 ms, total: 35.8 s\n",
                        "Wall time: 35.7 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Эксперименты с Stacking Classifier ===\\n\")\n",
                "\n",
                "n_splits_values = [2, 3, 4, 5, 6, 7]\n",
                "passthrough_values = [True, False]\n",
                "stacking_experiments = []\n",
                "\n",
                "for n_splits in n_splits_values:\n",
                "    for passthrough in passthrough_values:\n",
                "        print(f\"\\nТестируем n_splits={n_splits}, passthrough={passthrough}\")\n",
                "        \n",
                "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
                "        \n",
                "        stacking_clf = StackingClassifier(\n",
                "            estimators=[\n",
                "                ('svm', svm_best),\n",
                "                ('dt', dt_best),\n",
                "                ('rf', rf_best)\n",
                "            ],\n",
                "            final_estimator=LogisticRegression(solver='liblinear'),\n",
                "            cv=cv,\n",
                "            passthrough=passthrough\n",
                "        )\n",
                "        \n",
                "        stacking_clf.fit(X_train, y_train)\n",
                "        pred = stacking_clf.predict(X_valid)\n",
                "        \n",
                "        accuracy = accuracy_score(y_valid, pred)\n",
                "        precision = precision_score(y_valid, pred, average='weighted')\n",
                "        recall = recall_score(y_valid, pred, average='weighted')\n",
                "        \n",
                "        stacking_experiments.append({\n",
                "            'n_splits': n_splits,\n",
                "            'passthrough': passthrough,\n",
                "            'accuracy': accuracy,\n",
                "            'precision': precision,\n",
                "            'recall': recall,\n",
                "            'model': stacking_clf\n",
                "        })\n",
                "        \n",
                "        print(f\"accuracy is {accuracy:.5f}\")\n",
                "        print(f\"precision is {precision:.5f}\")\n",
                "        print(f\"recall is {recall:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 213,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Лучшие параметры stacking classifier:\n",
                        "n_splits: 4\n",
                        "passthrough: True\n",
                        "Точность на валидации: 0.91111\n",
                        "Precision на валидации: 0.91327\n",
                        "\n",
                        "Лучший Stacking Classifier - результаты на тестовом наборе:\n",
                        "accuracy is 0.90533\n",
                        "precision is 0.90844\n",
                        "recall is 0.90533\n"
                    ]
                }
            ],
            "source": [
                "best_stacking = max(stacking_experiments, key=lambda x: (x['accuracy'], x['precision']))\n",
                "print(f\"Лучшие параметры stacking classifier:\")\n",
                "print(f\"n_splits: {best_stacking['n_splits']}\")\n",
                "print(f\"passthrough: {best_stacking['passthrough']}\")\n",
                "print(f\"Точность на валидации: {best_stacking['accuracy']:.5f}\")\n",
                "print(f\"Precision на валидации: {best_stacking['precision']:.5f}\")\n",
                "\n",
                "best_stacking_model = best_stacking['model']\n",
                "stacking_test_pred = best_stacking_model.predict(X_test)\n",
                "stacking_test_accuracy = accuracy_score(y_test, stacking_test_pred)\n",
                "stacking_test_precision = precision_score(y_test, stacking_test_pred, average='weighted')\n",
                "stacking_test_recall = recall_score(y_test, stacking_test_pred, average='weighted')\n",
                "\n",
                "print(f\"\\nЛучший Stacking Classifier - результаты на тестовом наборе:\")\n",
                "print(f\"accuracy is {stacking_test_accuracy:.5f}\")\n",
                "print(f\"precision is {stacking_test_precision:.5f}\")\n",
                "print(f\"recall is {stacking_test_recall:.5f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Predictions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
                "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
                "3. Save the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 214,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== СРАВНЕНИЕ ФИНАЛЬНЫХ МОДЕЛЕЙ ===\n",
                        "\n",
                        "Производительность всех моделей на тестовом наборе:\n",
                        "SVM: accuracy=0.87778, precision=0.88162\n",
                        "Decision Tree: accuracy=0.86667, precision=0.87170\n",
                        "Random Forest: accuracy=0.89630, precision=0.89698\n",
                        "Best Voting: accuracy=0.90533, precision=0.90881\n",
                        "Best Bagging: accuracy=0.85503, precision=0.86157\n",
                        "Best Stacking: accuracy=0.90533, precision=0.90844\n",
                        "\n",
                        "Лучшая модель: Best Voting\n",
                        "Лучшая точность на тесте: 0.90533\n",
                        "Лучший precision на тесте: 0.90881\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== СРАВНЕНИЕ ФИНАЛЬНЫХ МОДЕЛЕЙ ===\\n\")\n",
                "\n",
                "all_models = {\n",
                "    'SVM': {'accuracy': svm_accuracy, 'precision': svm_precision, 'model': svm_best},\n",
                "    'Decision Tree': {'accuracy': dt_accuracy, 'precision': dt_precision, 'model': dt_best},\n",
                "    'Random Forest': {'accuracy': rf_accuracy, 'precision': rf_precision, 'model': rf_best},\n",
                "    'Best Voting': {'accuracy': voting_test_accuracy, 'precision': voting_test_precision, 'model': best_voting_model},\n",
                "    'Best Bagging': {'accuracy': bagging_test_accuracy, 'precision': bagging_test_precision, 'model': best_bagging_model},\n",
                "    'Best Stacking': {'accuracy': stacking_test_accuracy, 'precision': stacking_test_precision, 'model': best_stacking_model}\n",
                "}\n",
                "\n",
                "print(\"Производительность всех моделей на тестовом наборе:\")\n",
                "for model_name, metrics in all_models.items():\n",
                "    print(f\"{model_name}: accuracy={metrics['accuracy']:.5f}, precision={metrics['precision']:.5f}\")\n",
                "\n",
                "best_model_name = max(all_models.keys(), key=lambda x: (all_models[x]['accuracy'], all_models[x]['precision']))\n",
                "best_final_model = all_models[best_model_name]['model']\n",
                "best_final_accuracy = all_models[best_model_name]['accuracy']\n",
                "best_final_precision = all_models[best_model_name]['precision']\n",
                "\n",
                "print(f\"\\nЛучшая модель: {best_model_name}\")\n",
                "print(f\"Лучшая точность на тесте: {best_final_accuracy:.5f}\")\n",
                "print(f\"Лучший precision на тесте: {best_final_precision:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 215,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Анализ ошибок ===\n",
                        "\n",
                        "Матрица ошибок (полный датасет):\n",
                        "[[123   2   0   1   0   1   9]\n",
                        " [  1 263   2   3   0   4   1]\n",
                        " [  0   2 141   5   0   1   0]\n",
                        " [  0   2   0 389   0   2   3]\n",
                        " [  0   0   0   0 101   3   0]\n",
                        " [  0   1   0   4   0 258   8]\n",
                        " [  1   0   0   4   0   6 345]]\n",
                        "\n",
                        "Процент ошибок по дням недели (% от общего количества образцов этого класса):\n",
                        "Понедельник (класс 0): 9.56% ошибок (13/136 ошибок)\n",
                        "Вторник (класс 1): 4.01% ошибок (11/274 ошибок)\n",
                        "Среда (класс 2): 5.37% ошибок (8/149 ошибок)\n",
                        "Четверг (класс 3): 1.77% ошибок (7/396 ошибок)\n",
                        "Пятница (класс 4): 2.88% ошибок (3/104 ошибок)\n",
                        "Суббота (класс 5): 4.80% ошибок (13/271 ошибок)\n",
                        "Воскресенье (класс 6): 3.09% ошибок (11/356 ошибок)\n",
                        "\n",
                        "День недели с наибольшими ошибками: Понедельник (9.56% ошибок)\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Анализ ошибок ===\\n\")\n",
                "\n",
                "full_predictions = best_final_model.predict(X)\n",
                "\n",
                "cm_full = confusion_matrix(y, full_predictions)\n",
                "print(\"Матрица ошибок (полный датасет):\")\n",
                "print(cm_full)\n",
                "\n",
                "weekdays = ['Понедельник', 'Вторник', 'Среда', 'Четверг', 'Пятница', 'Суббота', 'Воскресенье']\n",
                "weekday_errors = {}\n",
                "\n",
                "print(\"\\nПроцент ошибок по дням недели (% от общего количества образцов этого класса):\")\n",
                "for i, day in enumerate(weekdays):\n",
                "    total_samples = sum(cm_full[i, :])\n",
                "    correct_predictions = cm_full[i, i]\n",
                "    if total_samples > 0:\n",
                "        error_rate = (total_samples - correct_predictions) / total_samples * 100\n",
                "        weekday_errors[day] = error_rate\n",
                "        print(f\"{day} (класс {i}): {error_rate:.2f}% ошибок ({total_samples - correct_predictions}/{total_samples} ошибок)\")\n",
                "\n",
                "worst_weekday = max(weekday_errors, key=weekday_errors.get) if weekday_errors else 'Нет'\n",
                "worst_weekday_rate = weekday_errors[worst_weekday] if weekday_errors else 0\n",
                "print(f\"\\nДень недели с наибольшими ошибками: {worst_weekday} ({worst_weekday_rate:.2f}% ошибок)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 216,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Анализ ошибок по Labname ===\n",
                        "\n",
                        "Процент ошибок по labname:\n",
                        "code_rvw: 6.10% ошибок (5/82 ошибок)\n",
                        "lab02: 0.00% ошибок (0/2 ошибок)\n",
                        "lab03: 100.00% ошибок (1/1 ошибок)\n",
                        "lab03s: 0.00% ошибок (0/1 ошибок)\n",
                        "lab05s: 11.11% ошибок (4/36 ошибок)\n",
                        "laba04: 5.62% ошибок (10/178 ошибок)\n",
                        "laba04s: 9.62% ошибок (10/104 ошибок)\n",
                        "laba05: 1.35% ошибок (3/222 ошибок)\n",
                        "laba06: 6.25% ошибок (3/48 ошибок)\n",
                        "laba06s: 6.56% ошибок (4/61 ошибок)\n",
                        "project1: 2.73% ошибок (26/951 ошибок)\n",
                        "\n",
                        "Labname с наибольшими ошибками: lab03 (100.00% ошибок)\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Анализ ошибок по Labname ===\\n\")\n",
                "\n",
                "error_df = df.copy()\n",
                "error_df['predicted'] = full_predictions\n",
                "error_df['is_error'] = (error_df['dayofweek'] != error_df['predicted'])\n",
                "\n",
                "labname_cols = [col for col in df.columns if col.startswith('labname_')]\n",
                "\n",
                "labname_errors = {}\n",
                "print(\"Процент ошибок по labname:\")\n",
                "for col in labname_cols:\n",
                "    lab_name = col.replace('labname_', '')\n",
                "    lab_samples = error_df[error_df[col] == 1.0]\n",
                "    if len(lab_samples) > 0:\n",
                "        error_count = lab_samples['is_error'].sum()\n",
                "        error_rate = lab_samples['is_error'].mean() * 100\n",
                "        labname_errors[lab_name] = error_rate\n",
                "        print(f\"{lab_name}: {error_rate:.2f}% ошибок ({error_count}/{len(lab_samples)} ошибок)\")\n",
                "\n",
                "if labname_errors:\n",
                "    worst_lab = max(labname_errors, key=labname_errors.get)\n",
                "    worst_lab_rate = labname_errors[worst_lab]\n",
                "    print(f\"\\nLabname с наибольшими ошибками: {worst_lab} ({worst_lab_rate:.2f}% ошибок)\")\n",
                "else:\n",
                "    worst_lab = 'Нет'\n",
                "    worst_lab_rate = 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 217,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Анализ ошибок по пользователям ===\n",
                        "\n",
                        "Топ-10 пользователей с наибольшим процентом ошибок:\n",
                        "user_user_22: 28.57% ошибок (2/7 ошибок)\n",
                        "user_user_6: 25.00% ошибок (3/12 ошибок)\n",
                        "user_user_17: 14.71% ошибок (5/34 ошибок)\n",
                        "user_user_16: 6.25% ошибок (2/32 ошибок)\n",
                        "user_user_15: 5.88% ошибок (1/17 ошибок)\n",
                        "user_user_2: 5.79% ошибок (7/121 ошибок)\n",
                        "user_user_18: 5.71% ошибок (2/35 ошибок)\n",
                        "user_user_30: 5.13% ошибок (2/39 ошибок)\n",
                        "user_user_25: 5.00% ошибок (6/120 ошибок)\n",
                        "user_user_29: 4.69% ошибок (3/64 ошибок)\n",
                        "\n",
                        "Пользователь с наибольшими ошибками: user_user_22 (28.57% ошибок)\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Анализ ошибок по пользователям ===\\n\")\n",
                "\n",
                "uid_cols = [col for col in df.columns if col.startswith('uid_')]\n",
                "\n",
                "user_errors = {}\n",
                "for col in uid_cols:\n",
                "    user_name = col.replace('uid_', '')\n",
                "    user_samples = error_df[error_df[col] == 1.0]\n",
                "    if len(user_samples) > 5:\n",
                "        error_count = user_samples['is_error'].sum()\n",
                "        error_rate = user_samples['is_error'].mean() * 100\n",
                "        user_errors[user_name] = {\n",
                "            'error_rate': error_rate, \n",
                "            'total_samples': len(user_samples), \n",
                "            'errors': error_count\n",
                "        }\n",
                "\n",
                "print(\"Топ-10 пользователей с наибольшим процентом ошибок:\")\n",
                "sorted_users = sorted(user_errors.items(), key=lambda x: x[1]['error_rate'], reverse=True)[:10]\n",
                "for user, stats in sorted_users:\n",
                "    print(f\"user_{user}: {stats['error_rate']:.2f}% ошибок ({int(stats['errors'])}/{stats['total_samples']} ошибок)\")\n",
                "\n",
                "if sorted_users:\n",
                "    worst_user = f\"user_{sorted_users[0][0]}\"\n",
                "    worst_user_rate = sorted_users[0][1]['error_rate']\n",
                "    print(f\"\\nПользователь с наибольшими ошибками: {worst_user} ({worst_user_rate:.2f}% ошибок)\")\n",
                "else:\n",
                "    worst_user = 'Нет'\n",
                "    worst_user_rate = 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Лучшая ансамблевая модель сохранена как: work/src/ex03/model/best_model_ensembles.joblib\n",
                        "Информация о модели сохранена в: work/src/ex03/model/model_info_ensembles.json\n"
                    ]
                }
            ],
            "source": [
                "model_filename = 'work/src/ex03/model/best_model_ensembles.joblib'\n",
                "joblib.dump(best_final_model, model_filename)\n",
                "print(f\"Лучшая ансамблевая модель сохранена как: {model_filename}\")\n",
                "\n",
                "model_info = {\n",
                "    'best_model_type': best_model_name,\n",
                "    'test_accuracy': float(best_final_accuracy),\n",
                "    'test_precision': float(best_final_precision),\n",
                "    'error_analysis': {\n",
                "        'worst_weekday': worst_weekday,\n",
                "        'worst_weekday_error_rate': float(worst_weekday_rate),\n",
                "        'worst_labname': worst_lab,\n",
                "        'worst_labname_error_rate': float(worst_lab_rate),\n",
                "        'worst_user': worst_user,\n",
                "        'worst_user_error_rate': float(worst_user_rate)\n",
                "    },\n",
                "    'all_models_performance': {\n",
                "        name: {'accuracy': float(metrics['accuracy']), 'precision': float(metrics['precision'])} \n",
                "        for name, metrics in all_models.items()\n",
                "    }\n",
                "}\n",
                "\n",
                "info_filename = 'work/src/ex03/model/model_info_ensembles.json'\n",
                "with open(info_filename, 'w') as f:\n",
                "    json.dump(model_info, f, indent=2)\n",
                "\n",
                "print(f\"Информация о модели сохранена в файл: {info_filename}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
