{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 09. Exercise 00\n",
                "# Regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Запуск контейнера с нужными версиями\n",
                "\n",
                "docker run -d \\\n",
                "  --platform linux/amd64 \\\n",
                "  -p 8888:8888 \\\n",
                "  -v $(pwd):/home/jovyan/work \\\n",
                "  --name sklearn \\\n",
                "  jupyter/scipy-notebook:python-3.8 \\\n",
                "  bash -c \"pip install scikit-learn==0.23.1 && start-notebook.sh --NotebookApp.token=''\"\n",
                "\n",
                "#### выбираем правильный kernel в vscode на localhost (который отдает докер)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 189,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Python версия: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n",
                        "[GCC 10.3.0]\n",
                        "scikit-learn версия: 0.23.1\n",
                        "pandas версия: 1.5.0\n",
                        "numpy версия: 1.23.3\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "print(\"Python версия:\", sys.version)\n",
                "\n",
                "import sklearn\n",
                "print(\"scikit-learn версия:\", sklearn.__version__)\n",
                "\n",
                "import pandas as pd\n",
                "print(\"pandas версия:\", pd.__version__)\n",
                "\n",
                "import numpy as np\n",
                "print(\"numpy версия:\", np.__version__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 190,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import joblib\n",
                "import json"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
                "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 191,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Размерность данных: (1686, 44)\n",
                        "Колонки в файле: ['numTrials', 'hour', 'uid_user_0', 'uid_user_1', 'uid_user_10', 'uid_user_11', 'uid_user_12', 'uid_user_13', 'uid_user_14', 'uid_user_15', 'uid_user_16', 'uid_user_17', 'uid_user_18', 'uid_user_19', 'uid_user_2', 'uid_user_20', 'uid_user_21', 'uid_user_22', 'uid_user_23', 'uid_user_24', 'uid_user_25', 'uid_user_26', 'uid_user_27', 'uid_user_28', 'uid_user_29', 'uid_user_3', 'uid_user_30', 'uid_user_31', 'uid_user_4', 'uid_user_6', 'uid_user_7', 'uid_user_8', 'labname_code_rvw', 'labname_lab02', 'labname_lab03', 'labname_lab03s', 'labname_lab05s', 'labname_laba04', 'labname_laba04s', 'labname_laba05', 'labname_laba06', 'labname_laba06s', 'labname_project1', 'dayofweek']\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>numTrials</th>\n",
                            "      <th>hour</th>\n",
                            "      <th>uid_user_0</th>\n",
                            "      <th>uid_user_1</th>\n",
                            "      <th>uid_user_10</th>\n",
                            "      <th>uid_user_11</th>\n",
                            "      <th>uid_user_12</th>\n",
                            "      <th>uid_user_13</th>\n",
                            "      <th>uid_user_14</th>\n",
                            "      <th>uid_user_15</th>\n",
                            "      <th>...</th>\n",
                            "      <th>labname_lab03</th>\n",
                            "      <th>labname_lab03s</th>\n",
                            "      <th>labname_lab05s</th>\n",
                            "      <th>labname_laba04</th>\n",
                            "      <th>labname_laba04s</th>\n",
                            "      <th>labname_laba05</th>\n",
                            "      <th>labname_laba06</th>\n",
                            "      <th>labname_laba06s</th>\n",
                            "      <th>labname_project1</th>\n",
                            "      <th>dayofweek</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>-0.788667</td>\n",
                            "      <td>-2.562352</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>-0.756764</td>\n",
                            "      <td>-2.562352</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>-0.724861</td>\n",
                            "      <td>-2.562352</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>-0.692958</td>\n",
                            "      <td>-2.562352</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>-0.661055</td>\n",
                            "      <td>-2.562352</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 44 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   numTrials      hour  uid_user_0  uid_user_1  uid_user_10  uid_user_11  \\\n",
                            "0  -0.788667 -2.562352         0.0         0.0          0.0          0.0   \n",
                            "1  -0.756764 -2.562352         0.0         0.0          0.0          0.0   \n",
                            "2  -0.724861 -2.562352         0.0         0.0          0.0          0.0   \n",
                            "3  -0.692958 -2.562352         0.0         0.0          0.0          0.0   \n",
                            "4  -0.661055 -2.562352         0.0         0.0          0.0          0.0   \n",
                            "\n",
                            "   uid_user_12  uid_user_13  uid_user_14  uid_user_15  ...  labname_lab03  \\\n",
                            "0          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "1          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "2          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "3          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "4          0.0          0.0          0.0          0.0  ...            0.0   \n",
                            "\n",
                            "   labname_lab03s  labname_lab05s  labname_laba04  labname_laba04s  \\\n",
                            "0             0.0             0.0             0.0              0.0   \n",
                            "1             0.0             0.0             0.0              0.0   \n",
                            "2             0.0             0.0             0.0              0.0   \n",
                            "3             0.0             0.0             0.0              0.0   \n",
                            "4             0.0             0.0             0.0              0.0   \n",
                            "\n",
                            "   labname_laba05  labname_laba06  labname_laba06s  labname_project1  \\\n",
                            "0             0.0             0.0              0.0               1.0   \n",
                            "1             0.0             0.0              0.0               1.0   \n",
                            "2             0.0             0.0              0.0               1.0   \n",
                            "3             0.0             0.0              0.0               1.0   \n",
                            "4             0.0             0.0              0.0               1.0   \n",
                            "\n",
                            "   dayofweek  \n",
                            "0          4  \n",
                            "1          4  \n",
                            "2          4  \n",
                            "3          4  \n",
                            "4          4  \n",
                            "\n",
                            "[5 rows x 44 columns]"
                        ]
                    },
                    "execution_count": 191,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df = pd.read_csv('work/src/data/dayofweek.csv')\n",
                "print(f\"Размерность данных: {df.shape}\")\n",
                "print(f\"Колонки в файле: {df.columns.tolist()}\")\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 192,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Распределение целевой переменной:\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0    136\n",
                            "1    274\n",
                            "2    149\n",
                            "3    396\n",
                            "4    104\n",
                            "5    271\n",
                            "6    356\n",
                            "Name: dayofweek, dtype: int64"
                        ]
                    },
                    "execution_count": 192,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "print(\"Распределение целевой переменной:\")\n",
                "df['dayofweek'].value_counts().sort_index()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Пропущенные значения:\n",
                        "numTrials           0\n",
                        "hour                0\n",
                        "uid_user_0          0\n",
                        "uid_user_1          0\n",
                        "uid_user_10         0\n",
                        "uid_user_11         0\n",
                        "uid_user_12         0\n",
                        "uid_user_13         0\n",
                        "uid_user_14         0\n",
                        "uid_user_15         0\n",
                        "uid_user_16         0\n",
                        "uid_user_17         0\n",
                        "uid_user_18         0\n",
                        "uid_user_19         0\n",
                        "uid_user_2          0\n",
                        "uid_user_20         0\n",
                        "uid_user_21         0\n",
                        "uid_user_22         0\n",
                        "uid_user_23         0\n",
                        "uid_user_24         0\n",
                        "uid_user_25         0\n",
                        "uid_user_26         0\n",
                        "uid_user_27         0\n",
                        "uid_user_28         0\n",
                        "uid_user_29         0\n",
                        "uid_user_3          0\n",
                        "uid_user_30         0\n",
                        "uid_user_31         0\n",
                        "uid_user_4          0\n",
                        "uid_user_6          0\n",
                        "uid_user_7          0\n",
                        "uid_user_8          0\n",
                        "labname_code_rvw    0\n",
                        "labname_lab02       0\n",
                        "labname_lab03       0\n",
                        "labname_lab03s      0\n",
                        "labname_lab05s      0\n",
                        "labname_laba04      0\n",
                        "labname_laba04s     0\n",
                        "labname_laba05      0\n",
                        "labname_laba06      0\n",
                        "labname_laba06s     0\n",
                        "labname_project1    0\n",
                        "dayofweek           0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\nПропущенные значения:\")\n",
                "print(df.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 194,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Размерность признаков: (1686, 43)\n",
                        "Размерность целевой переменной: (1686,)\n",
                        "\n",
                        "Информация о признаках:\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 1686 entries, 0 to 1685\n",
                        "Data columns (total 43 columns):\n",
                        " #   Column            Non-Null Count  Dtype  \n",
                        "---  ------            --------------  -----  \n",
                        " 0   numTrials         1686 non-null   float64\n",
                        " 1   hour              1686 non-null   float64\n",
                        " 2   uid_user_0        1686 non-null   float64\n",
                        " 3   uid_user_1        1686 non-null   float64\n",
                        " 4   uid_user_10       1686 non-null   float64\n",
                        " 5   uid_user_11       1686 non-null   float64\n",
                        " 6   uid_user_12       1686 non-null   float64\n",
                        " 7   uid_user_13       1686 non-null   float64\n",
                        " 8   uid_user_14       1686 non-null   float64\n",
                        " 9   uid_user_15       1686 non-null   float64\n",
                        " 10  uid_user_16       1686 non-null   float64\n",
                        " 11  uid_user_17       1686 non-null   float64\n",
                        " 12  uid_user_18       1686 non-null   float64\n",
                        " 13  uid_user_19       1686 non-null   float64\n",
                        " 14  uid_user_2        1686 non-null   float64\n",
                        " 15  uid_user_20       1686 non-null   float64\n",
                        " 16  uid_user_21       1686 non-null   float64\n",
                        " 17  uid_user_22       1686 non-null   float64\n",
                        " 18  uid_user_23       1686 non-null   float64\n",
                        " 19  uid_user_24       1686 non-null   float64\n",
                        " 20  uid_user_25       1686 non-null   float64\n",
                        " 21  uid_user_26       1686 non-null   float64\n",
                        " 22  uid_user_27       1686 non-null   float64\n",
                        " 23  uid_user_28       1686 non-null   float64\n",
                        " 24  uid_user_29       1686 non-null   float64\n",
                        " 25  uid_user_3        1686 non-null   float64\n",
                        " 26  uid_user_30       1686 non-null   float64\n",
                        " 27  uid_user_31       1686 non-null   float64\n",
                        " 28  uid_user_4        1686 non-null   float64\n",
                        " 29  uid_user_6        1686 non-null   float64\n",
                        " 30  uid_user_7        1686 non-null   float64\n",
                        " 31  uid_user_8        1686 non-null   float64\n",
                        " 32  labname_code_rvw  1686 non-null   float64\n",
                        " 33  labname_lab02     1686 non-null   float64\n",
                        " 34  labname_lab03     1686 non-null   float64\n",
                        " 35  labname_lab03s    1686 non-null   float64\n",
                        " 36  labname_lab05s    1686 non-null   float64\n",
                        " 37  labname_laba04    1686 non-null   float64\n",
                        " 38  labname_laba04s   1686 non-null   float64\n",
                        " 39  labname_laba05    1686 non-null   float64\n",
                        " 40  labname_laba06    1686 non-null   float64\n",
                        " 41  labname_laba06s   1686 non-null   float64\n",
                        " 42  labname_project1  1686 non-null   float64\n",
                        "dtypes: float64(43)\n",
                        "memory usage: 566.5 KB\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "X = df.drop('dayofweek', axis=1)\n",
                "y = df['dayofweek']\n",
                "\n",
                "print(\"Размерность признаков:\", X.shape)\n",
                "print(\"Размерность целевой переменной:\", y.shape)\n",
                "print(\"\\nИнформация о признаках:\")\n",
                "print(X.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 195,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Размерность тренировочного набора: (1348, 43)\n",
                        "Размерность тестового набора: (338, 43)\n",
                        "\n",
                        "Распределение в тренировочной выборке:\n",
                        "0    109\n",
                        "1    219\n",
                        "2    119\n",
                        "3    316\n",
                        "4     83\n",
                        "5    217\n",
                        "6    285\n",
                        "Name: dayofweek, dtype: int64\n",
                        "Распределение в тестовой выборке:\n",
                        "0    27\n",
                        "1    55\n",
                        "2    30\n",
                        "3    80\n",
                        "4    21\n",
                        "5    54\n",
                        "6    71\n",
                        "Name: dayofweek, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=0.2, \n",
                "    random_state=21, \n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(\"Размерность тренировочного набора:\", X_train.shape)\n",
                "print(\"Размерность тестового набора:\", X_test.shape)\n",
                "print(\"\\nРаспределение в тренировочной выборке:\")\n",
                "print(y_train.value_counts().sort_index())\n",
                "print(\"Распределение в тестовой выборке:\")\n",
                "print(y_test.value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Функция для тестов"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 196,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model_cv(model, X_train, y_train, cv_folds=10):\n",
                "    \"\"\"\n",
                "    Оценка модели с помощью стратифицированной k-fold кросс-валидации\n",
                "    \"\"\"\n",
                "    skf = StratifiedKFold(n_splits=cv_folds)\n",
                "    \n",
                "    train_scores = []\n",
                "    val_scores = []\n",
                "    \n",
                "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
                "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
                "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
                "        \n",
                "        model.fit(X_fold_train, y_fold_train)\n",
                "        \n",
                "        train_score = model.score(X_fold_train, y_fold_train)\n",
                "        val_score = model.score(X_fold_val, y_fold_val)\n",
                "        \n",
                "        train_scores.append(train_score)\n",
                "        val_scores.append(val_score)\n",
                "        \n",
                "        print(f\"train -  {train_score:.5f}   |   valid -  {val_score:.5f}\")\n",
                "    \n",
                "    avg_val_score = np.mean(val_scores)\n",
                "    std_val_score = np.std(val_scores)\n",
                "    \n",
                "    print(f\"Average accuracy on crossval is {avg_val_score:.5f}\")\n",
                "    print(f\"Std is {std_val_score:.5f}\\n\")\n",
                "    \n",
                "    return avg_val_score, std_val_score"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Logreg regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### a. Default regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
                "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
                "\n",
                "\n",
                "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
                "\n",
                "```\n",
                "train -  0.62902   |   valid -  0.59259\n",
                "train -  0.64633   |   valid -  0.62963\n",
                "train -  0.63479   |   valid -  0.56296\n",
                "train -  0.65622   |   valid -  0.61481\n",
                "train -  0.63397   |   valid -  0.57778\n",
                "train -  0.64056   |   valid -  0.59259\n",
                "train -  0.64138   |   valid -  0.65926\n",
                "train -  0.65952   |   valid -  0.56296\n",
                "train -  0.64333   |   valid -  0.59701\n",
                "train -  0.63674   |   valid -  0.62687\n",
                "Average accuracy on crossval is 0.60165\n",
                "Std is 0.02943\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 197,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logistic Regression - Базовая модель (стандартная регуляризация):\n",
                        "train -  0.62902   |   valid -  0.59259\n",
                        "train -  0.64633   |   valid -  0.62963\n",
                        "train -  0.63479   |   valid -  0.56296\n",
                        "train -  0.65622   |   valid -  0.61481\n",
                        "train -  0.63397   |   valid -  0.57778\n",
                        "train -  0.64056   |   valid -  0.59259\n",
                        "train -  0.64138   |   valid -  0.65926\n",
                        "train -  0.65952   |   valid -  0.56296\n",
                        "train -  0.64333   |   valid -  0.59701\n",
                        "train -  0.63674   |   valid -  0.62687\n",
                        "Average accuracy on crossval is 0.60165\n",
                        "Std is 0.02943\n",
                        "\n",
                        "CPU times: user 3.94 s, sys: 6.27 s, total: 10.2 s\n",
                        "Wall time: 1.05 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "logreg_baseline = LogisticRegression(random_state=21, fit_intercept=False)\n",
                "\n",
                "print(\"Logistic Regression - Базовая модель (стандартная регуляризация):\")\n",
                "logreg_baseline_score, logreg_baseline_std = evaluate_model_cv(logreg_baseline, X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b. Optimizing regularization parameters"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 198,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Logistic Regression с разными типами регуляризации ===\n",
                        "\n",
                        "1. Без регуляризации (penalty='none', lbfgs):\n",
                        "train -  0.66694   |   valid -  0.63704\n",
                        "train -  0.65787   |   valid -  0.65926\n",
                        "train -  0.66694   |   valid -  0.57778\n",
                        "train -  0.66529   |   valid -  0.62963\n",
                        "train -  0.66694   |   valid -  0.62222\n",
                        "train -  0.65952   |   valid -  0.57778\n",
                        "train -  0.65045   |   valid -  0.69630\n",
                        "train -  0.68425   |   valid -  0.61481\n",
                        "train -  0.66474   |   valid -  0.62687\n",
                        "train -  0.65651   |   valid -  0.60448\n",
                        "Average accuracy on crossval is 0.62462\n",
                        "Std is 0.03379\n",
                        "\n",
                        "2. L1 регуляризация (penalty='l1', lbfgs):\n",
                        "НЕ ПОДДЕРЖИВАЕТСЯ\n",
                        "\n",
                        "3. L2 регуляризация (penalty='l2', lbfgs):\n",
                        "train -  0.62902   |   valid -  0.59259\n",
                        "train -  0.64633   |   valid -  0.62963\n",
                        "train -  0.63479   |   valid -  0.56296\n",
                        "train -  0.65622   |   valid -  0.61481\n",
                        "train -  0.63397   |   valid -  0.57778\n",
                        "train -  0.64056   |   valid -  0.59259\n",
                        "train -  0.64138   |   valid -  0.65926\n",
                        "train -  0.65952   |   valid -  0.56296\n",
                        "train -  0.64333   |   valid -  0.59701\n",
                        "train -  0.63674   |   valid -  0.62687\n",
                        "Average accuracy on crossval is 0.60165\n",
                        "Std is 0.02943\n",
                        "\n",
                        "4. Elastic Net регуляризация (penalty='elasticnet', lbfgs):\n",
                        "НЕ ПОДДЕРЖИВАЕТСЯ\n",
                        "\n",
                        "CPU times: user 21.3 s, sys: 35.8 s, total: 57.1 s\n",
                        "Wall time: 5.72 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Logistic Regression с разными типами регуляризации ===\\n\")\n",
                "\n",
                "print(\"1. Без регуляризации (penalty='none', lbfgs):\")\n",
                "logreg_none = LogisticRegression(random_state=21, fit_intercept=False, penalty='none', solver='lbfgs', max_iter=1000)\n",
                "logreg_none_score, _ = evaluate_model_cv(logreg_none, X_train, y_train)\n",
                "\n",
                "print(\"2. L1 регуляризация (penalty='l1', lbfgs):\")\n",
                "print(\"НЕ ПОДДЕРЖИВАЕТСЯ\\n\")\n",
                "\n",
                "print(\"3. L2 регуляризация (penalty='l2', lbfgs):\")\n",
                "logreg_l2 = LogisticRegression(random_state=21, fit_intercept=False, penalty='l2', solver='lbfgs', max_iter=1000)\n",
                "logreg_l2_score, _ = evaluate_model_cv(logreg_l2, X_train, y_train)\n",
                "\n",
                "print(\"4. Elastic Net регуляризация (penalty='elasticnet', lbfgs):\")\n",
                "print(\"НЕ ПОДДЕРЖИВАЕТСЯ\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 199,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "logreg_none_score: 0.6246158098396905\n",
                        "logreg_l2_score:   0.6016473189607519\n"
                    ]
                }
            ],
            "source": [
                "print(f\"logreg_none_score: {logreg_none_score}\")\n",
                "print(f\"logreg_l2_score:   {logreg_l2_score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 200,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1. Без регуляризации (penalty='none', liblinear):\n",
                        "НЕ ПОДДЕРЖИВАЕТСЯ\n",
                        "\n",
                        "2. L1 регуляризация (penalty='l1', liblinear):\n",
                        "train -  0.61830   |   valid -  0.54815\n",
                        "train -  0.62737   |   valid -  0.62222\n",
                        "train -  0.60511   |   valid -  0.54074\n",
                        "train -  0.63644   |   valid -  0.62222\n",
                        "train -  0.62407   |   valid -  0.55556\n",
                        "train -  0.62325   |   valid -  0.58519\n",
                        "train -  0.61253   |   valid -  0.63704\n",
                        "train -  0.64716   |   valid -  0.58519\n",
                        "train -  0.63015   |   valid -  0.59701\n",
                        "train -  0.61367   |   valid -  0.59701\n",
                        "Average accuracy on crossval is 0.58903\n",
                        "Std is 0.03129\n",
                        "\n",
                        "3. L2 регуляризация (penalty='l2', liblinear):\n",
                        "train -  0.61006   |   valid -  0.56296\n",
                        "train -  0.61665   |   valid -  0.61481\n",
                        "train -  0.61336   |   valid -  0.59259\n",
                        "train -  0.62902   |   valid -  0.60741\n",
                        "train -  0.60923   |   valid -  0.55556\n",
                        "train -  0.61500   |   valid -  0.57778\n",
                        "train -  0.61665   |   valid -  0.61481\n",
                        "train -  0.64056   |   valid -  0.53333\n",
                        "train -  0.62109   |   valid -  0.58209\n",
                        "train -  0.61120   |   valid -  0.57463\n",
                        "Average accuracy on crossval is 0.58160\n",
                        "Std is 0.02532\n",
                        "\n",
                        "4. Elastic Net регуляризация (penalty='elasticnet', liblinear):\n",
                        "НЕ ПОДДЕРЖИВАЕТСЯ\n",
                        "\n",
                        "CPU times: user 1.53 s, sys: 2.3 s, total: 3.83 s\n",
                        "Wall time: 383 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"1. Без регуляризации (penalty='none', liblinear):\")\n",
                "print(\"НЕ ПОДДЕРЖИВАЕТСЯ\\n\")\n",
                "\n",
                "print(\"2. L1 регуляризация (penalty='l1', liblinear):\")\n",
                "logreg_l1 = LogisticRegression(random_state=21, fit_intercept=False, penalty='l1', solver='liblinear', max_iter=1000)\n",
                "logreg_l1_score, _ = evaluate_model_cv(logreg_l1, X_train, y_train)\n",
                "\n",
                "print(\"3. L2 регуляризация (penalty='l2', liblinear):\")\n",
                "logreg_l2 = LogisticRegression(random_state=21, fit_intercept=False, penalty='l2', solver='liblinear', max_iter=1000)\n",
                "logreg_l2_score, _ = evaluate_model_cv(logreg_l2, X_train, y_train)\n",
                "\n",
                "print(\"4. Elastic Net регуляризация (penalty='elasticnet', liblinear):\")\n",
                "print(\"НЕ ПОДДЕРЖИВАЕТСЯ\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 201,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "logreg_l1_score: 0.5890326147042565\n",
                        "logreg_l2_score: 0.5815975677169707\n"
                    ]
                }
            ],
            "source": [
                "print(f\"logreg_l1_score: {logreg_l1_score}\")\n",
                "print(f\"logreg_l2_score: {logreg_l2_score}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 202,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1. Без регуляризации (penalty='none', saga):\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.66612   |   valid -  0.63704\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.65787   |   valid -  0.65926\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.66612   |   valid -  0.57778\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.66529   |   valid -  0.62963\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.66694   |   valid -  0.61481\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.65952   |   valid -  0.57778\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.65045   |   valid -  0.69630\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.68425   |   valid -  0.61481\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.66474   |   valid -  0.62687\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
                        "  warnings.warn(\"The max_iter was reached which means \"\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.65651   |   valid -  0.60448\n",
                        "Average accuracy on crossval is 0.62388\n",
                        "Std is 0.03392\n",
                        "\n",
                        "2. L1 регуляризация (penalty='l1', saga):\n",
                        "train -  0.63726   |   valid -  0.58519\n",
                        "train -  0.64221   |   valid -  0.61481\n",
                        "train -  0.62984   |   valid -  0.55556\n",
                        "train -  0.64386   |   valid -  0.60000\n",
                        "train -  0.63232   |   valid -  0.57778\n",
                        "train -  0.63644   |   valid -  0.57778\n",
                        "train -  0.63644   |   valid -  0.65926\n",
                        "train -  0.65622   |   valid -  0.57778\n",
                        "train -  0.64580   |   valid -  0.58955\n",
                        "train -  0.63839   |   valid -  0.62687\n",
                        "Average accuracy on crossval is 0.59646\n",
                        "Std is 0.02848\n",
                        "\n",
                        "3. L2 регуляризация (penalty='l2', saga):\n",
                        "train -  0.62902   |   valid -  0.59259\n",
                        "train -  0.64633   |   valid -  0.62963\n",
                        "train -  0.63479   |   valid -  0.56296\n",
                        "train -  0.65622   |   valid -  0.61481\n",
                        "train -  0.63397   |   valid -  0.57778\n",
                        "train -  0.64056   |   valid -  0.59259\n",
                        "train -  0.64221   |   valid -  0.65926\n",
                        "train -  0.65952   |   valid -  0.56296\n",
                        "train -  0.64333   |   valid -  0.59701\n",
                        "train -  0.63674   |   valid -  0.62687\n",
                        "Average accuracy on crossval is 0.60165\n",
                        "Std is 0.02943\n",
                        "\n",
                        "4. Elastic Net регуляризация (penalty='elasticnet'):\n",
                        "train -  0.63561   |   valid -  0.59259\n",
                        "train -  0.65210   |   valid -  0.62963\n",
                        "train -  0.63232   |   valid -  0.57037\n",
                        "train -  0.65045   |   valid -  0.60000\n",
                        "train -  0.63479   |   valid -  0.57778\n",
                        "train -  0.63479   |   valid -  0.58519\n",
                        "train -  0.63561   |   valid -  0.65185\n",
                        "train -  0.65375   |   valid -  0.56296\n",
                        "train -  0.64333   |   valid -  0.58209\n",
                        "train -  0.63756   |   valid -  0.62687\n",
                        "Average accuracy on crossval is 0.59793\n",
                        "Std is 0.02754\n",
                        "\n",
                        "CPU times: user 49.5 s, sys: 53.7 s, total: 1min 43s\n",
                        "Wall time: 22.7 s\n",
                        "Parser   : 112 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"1. Без регуляризации (penalty='none', saga):\")\n",
                "logreg_none = LogisticRegression(random_state=21, fit_intercept=False, penalty='none', solver='saga', max_iter=1000)\n",
                "logreg_none_score, _ = evaluate_model_cv(logreg_none, X_train, y_train)\n",
                "\n",
                "print(\"2. L1 регуляризация (penalty='l1', saga):\")\n",
                "logreg_l1 = LogisticRegression(random_state=21, fit_intercept=False, penalty='l1', solver='saga', max_iter=1000)\n",
                "logreg_l1_score, _ = evaluate_model_cv(logreg_l1, X_train, y_train)\n",
                "\n",
                "print(\"3. L2 регуляризация (penalty='l2', saga):\")\n",
                "logreg_l2 = LogisticRegression(random_state=21, fit_intercept=False, penalty='l2', solver='saga', max_iter=1000)\n",
                "logreg_l2_score, _ = evaluate_model_cv(logreg_l2, X_train, y_train)\n",
                "\n",
                "print(\"4. Elastic Net регуляризация (penalty='elasticnet'):\")\n",
                "logreg_elastic = LogisticRegression(random_state=21, fit_intercept=False, penalty='elasticnet', \n",
                "                                  solver='saga', l1_ratio=0.5, max_iter=1000)\n",
                "logreg_elastic_score, _ = evaluate_model_cv(logreg_elastic, X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Ошибка ConvergenceWarning означает, что алгоритм оптимизации не сошелся за максимальное количество итераций.\n",
                "SAGA - это итеративный алгоритм оптимизации, который пытается найти минимум функции потерь. \n",
                "В нашем случае он не успел \"дойти\" до оптимального решения за 1000 итераций (max_iter=1000).\n",
                "\n",
                "### Почему только \"No regularization\" не сходится:\n",
                "#### Без регуляризации:\n",
                "\n",
                "- Алгоритм пытается найти \"идеальные\" коэффициенты без ограничений\n",
                "- Может \"гнаться\" за переобучением на тренировочных данных\n",
                "- Функция потерь становится сложной и \"изрезанной\"\n",
                "- Алгоритм \"мечется\" в поисках глобального минимума\n",
                "- Результат: плохая сходимость, но высокая точность на train (0.66-0.68)\n",
                "\n",
                "#### С регуляризацией (L1, L2, Elastic Net):\n",
                "\n",
                "- Добавляется штраф за большие веса коэффициентов\n",
                "- Функция потерь становится более гладкой и выпуклой\n",
                "- Алгоритм \"знает куда идти\" - к более простому решению\n",
                "- Результат: быстрая сходимость, но чуть меньше переобучения\n",
                "\n",
                "#### В машинном обучении алгоритм ищет лучшие коэффициенты для модели:\n",
                "✅ Сошелся - алгоритм нашел оптимум и перестал улучшаться\n",
                "\n",
                "❌ Не сошелся - время кончилось (max_iter), а он все еще ищет"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 203,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "logreg_none_score: 0.6238750690989499\n",
                        "logreg_l1_score: 0.5964566058595908\n",
                        "logreg_l2_score: 0.6016473189607519\n",
                        "logreg_elastic_score: 0.5979325594250968\n"
                    ]
                }
            ],
            "source": [
                "print(f\"logreg_none_score: {logreg_none_score}\")\n",
                "print(f\"logreg_l1_score: {logreg_l1_score}\")\n",
                "print(f\"logreg_l2_score: {logreg_l2_score}\")\n",
                "print(f\"logreg_elastic_score: {logreg_elastic_score}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. SVM regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### a. Default regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
                "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
                "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 204,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SVM - Базовая модель (стандартная регуляризация):\n",
                        "train -  0.70486   |   valid -  0.65926\n",
                        "train -  0.69662   |   valid -  0.75556\n",
                        "train -  0.69415   |   valid -  0.62222\n",
                        "train -  0.70239   |   valid -  0.65185\n",
                        "train -  0.69085   |   valid -  0.65185\n",
                        "train -  0.68920   |   valid -  0.64444\n",
                        "train -  0.69250   |   valid -  0.72593\n",
                        "train -  0.70074   |   valid -  0.62222\n",
                        "train -  0.69605   |   valid -  0.61940\n",
                        "train -  0.71087   |   valid -  0.63433\n",
                        "Average accuracy on crossval is 0.65871\n",
                        "Std is 0.04359\n",
                        "\n",
                        "CPU times: user 4.22 s, sys: 731 ms, total: 4.95 s\n",
                        "Wall time: 3.8 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "svm_baseline = SVC(probability=True, kernel='linear', random_state=21)\n",
                "\n",
                "print(\"SVM - Базовая модель (стандартная регуляризация):\")\n",
                "svm_baseline_score, svm_baseline_std = evaluate_model_cv(svm_baseline, X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b. Optimizing regularization parameters"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. In the cells below try different values of the parameter `C`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 205,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== SVM с разными значениями C (сила регуляризации) ===\n",
                        "\n",
                        "SVM с C=0.01:\n",
                        "train -  0.37923   |   valid -  0.40000\n",
                        "train -  0.37923   |   valid -  0.40000\n",
                        "train -  0.38417   |   valid -  0.35556\n",
                        "train -  0.35449   |   valid -  0.36296\n",
                        "train -  0.38252   |   valid -  0.37037\n",
                        "train -  0.38087   |   valid -  0.38519\n",
                        "train -  0.37923   |   valid -  0.40000\n",
                        "train -  0.38252   |   valid -  0.37037\n",
                        "train -  0.38468   |   valid -  0.35075\n",
                        "train -  0.38386   |   valid -  0.35821\n",
                        "Average accuracy on crossval is 0.37534\n",
                        "Std is 0.01848\n",
                        "\n",
                        "SVM с C=0.1:\n",
                        "train -  0.58120   |   valid -  0.55556\n",
                        "train -  0.57543   |   valid -  0.56296\n",
                        "train -  0.57378   |   valid -  0.57037\n",
                        "train -  0.59275   |   valid -  0.57037\n",
                        "train -  0.58120   |   valid -  0.54815\n",
                        "train -  0.57955   |   valid -  0.54815\n",
                        "train -  0.57296   |   valid -  0.61481\n",
                        "train -  0.59192   |   valid -  0.54815\n",
                        "train -  0.59967   |   valid -  0.52985\n",
                        "train -  0.57825   |   valid -  0.57463\n",
                        "Average accuracy on crossval is 0.56230\n",
                        "Std is 0.02177\n",
                        "\n",
                        "SVM с C=1.0:\n",
                        "train -  0.70486   |   valid -  0.65926\n",
                        "train -  0.69662   |   valid -  0.75556\n",
                        "train -  0.69415   |   valid -  0.62222\n",
                        "train -  0.70239   |   valid -  0.65185\n",
                        "train -  0.69085   |   valid -  0.65185\n",
                        "train -  0.68920   |   valid -  0.64444\n",
                        "train -  0.69250   |   valid -  0.72593\n",
                        "train -  0.70074   |   valid -  0.62222\n",
                        "train -  0.69605   |   valid -  0.61940\n",
                        "train -  0.71087   |   valid -  0.63433\n",
                        "Average accuracy on crossval is 0.65871\n",
                        "Std is 0.04359\n",
                        "\n",
                        "SVM с C=10.0:\n",
                        "train -  0.75021   |   valid -  0.72593\n",
                        "train -  0.77741   |   valid -  0.82963\n",
                        "train -  0.78566   |   valid -  0.68148\n",
                        "train -  0.76834   |   valid -  0.73333\n",
                        "train -  0.75185   |   valid -  0.77778\n",
                        "train -  0.75598   |   valid -  0.68889\n",
                        "train -  0.76257   |   valid -  0.74074\n",
                        "train -  0.77411   |   valid -  0.68889\n",
                        "train -  0.78254   |   valid -  0.71642\n",
                        "train -  0.78418   |   valid -  0.69403\n",
                        "Average accuracy on crossval is 0.72771\n",
                        "Std is 0.04417\n",
                        "\n",
                        "SVM с C=100.0:\n",
                        "train -  0.78401   |   valid -  0.74815\n",
                        "train -  0.79720   |   valid -  0.84444\n",
                        "train -  0.80956   |   valid -  0.72593\n",
                        "train -  0.79060   |   valid -  0.76296\n",
                        "train -  0.79060   |   valid -  0.77778\n",
                        "train -  0.79637   |   valid -  0.74815\n",
                        "train -  0.78401   |   valid -  0.77037\n",
                        "train -  0.80462   |   valid -  0.73333\n",
                        "train -  0.79819   |   valid -  0.70896\n",
                        "train -  0.79901   |   valid -  0.73881\n",
                        "Average accuracy on crossval is 0.75589\n",
                        "Std is 0.03550\n",
                        "\n",
                        "CPU times: user 32.1 s, sys: 0 ns, total: 32.1 s\n",
                        "Wall time: 32.1 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== SVM с разными значениями C (сила регуляризации) ===\\n\")\n",
                "\n",
                "c_values = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
                "svm_scores = {}\n",
                "\n",
                "for c in c_values:\n",
                "    print(f\"SVM с C={c}:\")\n",
                "    svm_model = SVC(probability=True, kernel='linear', random_state=21, C=c)\n",
                "    score, _ = evaluate_model_cv(svm_model, X_train, y_train)\n",
                "    svm_scores[c] = score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 206,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Сводка результатов SVM ===\n",
                        "\n",
                        "Базовая модель (C=1.0): 0.65871\n",
                        "C=0.01: 0.37534\n",
                        "C=0.1: 0.56230\n",
                        "C=1.0: 0.65871\n",
                        "C=10.0: 0.72771\n",
                        "C=100.0: 0.75589\n",
                        "\n",
                        "Лучшее значение C: 100.0 с результатом: 0.75589\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Сводка результатов SVM ===\\n\")\n",
                "print(f\"Базовая модель (C=1.0): {svm_baseline_score:.5f}\")\n",
                "for c, score in svm_scores.items():\n",
                "    print(f\"C={c}: {score:.5f}\")\n",
                "\n",
                "best_c = max(svm_scores, key=svm_scores.get)\n",
                "print(f\"\\nЛучшее значение C: {best_c} с результатом: {svm_scores[best_c]:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 207,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.7558872305140961"
                        ]
                    },
                    "execution_count": 207,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "svm_best = SVC(probability=True, kernel='linear', random_state=21, C=best_c)\n",
                "svm_best_score = svm_scores[best_c]\n",
                "\n",
                "svm_best_score"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Tree"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### a. Default regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
                "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
                "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 208,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Decision Tree - Базовая модель (max_depth=10):\n",
                        "train -  0.81039   |   valid -  0.74074\n",
                        "train -  0.77741   |   valid -  0.74074\n",
                        "train -  0.83347   |   valid -  0.70370\n",
                        "train -  0.79720   |   valid -  0.76296\n",
                        "train -  0.82440   |   valid -  0.75556\n",
                        "train -  0.80379   |   valid -  0.68889\n",
                        "train -  0.80709   |   valid -  0.76296\n",
                        "train -  0.80132   |   valid -  0.65926\n",
                        "train -  0.80807   |   valid -  0.75373\n",
                        "train -  0.80478   |   valid -  0.68657\n",
                        "Average accuracy on crossval is 0.72551\n",
                        "Std is 0.03562\n",
                        "\n",
                        "CPU times: user 64.9 ms, sys: 0 ns, total: 64.9 ms\n",
                        "Wall time: 64 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "tree_baseline = DecisionTreeClassifier(max_depth=10, random_state=21)\n",
                "\n",
                "print(\"Decision Tree - Базовая модель (max_depth=10):\")\n",
                "tree_baseline_score, tree_baseline_std = evaluate_model_cv(tree_baseline, X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b. Optimizing regularization parameters"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. In the cells below try different values of the parameter `max_depth`.\n",
                "2. As a bonus, play with other regularization parameters trying to find the best combination."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 209,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Decision Tree с разными значениями max_depth ===\n",
                        "\n",
                        "Decision Tree с max_depth=3:\n",
                        "train -  0.49382   |   valid -  0.43704\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "train -  0.48887   |   valid -  0.48148\n",
                        "train -  0.50206   |   valid -  0.44444\n",
                        "train -  0.49629   |   valid -  0.49630\n",
                        "train -  0.48475   |   valid -  0.48889\n",
                        "train -  0.48969   |   valid -  0.48889\n",
                        "train -  0.48392   |   valid -  0.48148\n",
                        "train -  0.49052   |   valid -  0.40741\n",
                        "train -  0.48517   |   valid -  0.46269\n",
                        "train -  0.49176   |   valid -  0.42537\n",
                        "Average accuracy on crossval is 0.46140\n",
                        "Std is 0.02938\n",
                        "\n",
                        "Decision Tree с max_depth=5:\n",
                        "train -  0.59522   |   valid -  0.53333\n",
                        "train -  0.56307   |   valid -  0.53333\n",
                        "train -  0.60181   |   valid -  0.55556\n",
                        "train -  0.59604   |   valid -  0.57037\n",
                        "train -  0.60264   |   valid -  0.57778\n",
                        "train -  0.57955   |   valid -  0.53333\n",
                        "train -  0.58368   |   valid -  0.54815\n",
                        "train -  0.59275   |   valid -  0.51111\n",
                        "train -  0.58237   |   valid -  0.56716\n",
                        "train -  0.60132   |   valid -  0.50000\n",
                        "Average accuracy on crossval is 0.54301\n",
                        "Std is 0.02423\n",
                        "\n",
                        "Decision Tree с max_depth=7:\n",
                        "train -  0.70322   |   valid -  0.64444\n",
                        "train -  0.67271   |   valid -  0.68148\n",
                        "train -  0.68261   |   valid -  0.57037\n",
                        "train -  0.68425   |   valid -  0.65185\n",
                        "train -  0.70734   |   valid -  0.64444\n",
                        "train -  0.68755   |   valid -  0.60741\n",
                        "train -  0.69662   |   valid -  0.71111\n",
                        "train -  0.68590   |   valid -  0.63704\n",
                        "train -  0.69357   |   valid -  0.70149\n",
                        "train -  0.70758   |   valid -  0.64925\n",
                        "Average accuracy on crossval is 0.64989\n",
                        "Std is 0.03971\n",
                        "\n",
                        "Decision Tree с max_depth=10:\n",
                        "train -  0.81039   |   valid -  0.74074\n",
                        "train -  0.77741   |   valid -  0.74074\n",
                        "train -  0.83347   |   valid -  0.70370\n",
                        "train -  0.79720   |   valid -  0.76296\n",
                        "train -  0.82440   |   valid -  0.75556\n",
                        "train -  0.80379   |   valid -  0.68889\n",
                        "train -  0.80709   |   valid -  0.76296\n",
                        "train -  0.80132   |   valid -  0.65926\n",
                        "train -  0.80807   |   valid -  0.75373\n",
                        "train -  0.80478   |   valid -  0.68657\n",
                        "Average accuracy on crossval is 0.72551\n",
                        "Std is 0.03562\n",
                        "\n",
                        "Decision Tree с max_depth=15:\n",
                        "train -  0.95796   |   valid -  0.82222\n",
                        "train -  0.93075   |   valid -  0.83704\n",
                        "train -  0.95631   |   valid -  0.83704\n",
                        "train -  0.95301   |   valid -  0.86667\n",
                        "train -  0.95136   |   valid -  0.88889\n",
                        "train -  0.94724   |   valid -  0.82222\n",
                        "train -  0.95466   |   valid -  0.90370\n",
                        "train -  0.94971   |   valid -  0.87407\n",
                        "train -  0.95305   |   valid -  0.83582\n",
                        "train -  0.94316   |   valid -  0.85821\n",
                        "Average accuracy on crossval is 0.85459\n",
                        "Std is 0.02682\n",
                        "\n",
                        "Decision Tree с max_depth=20:\n",
                        "train -  0.98846   |   valid -  0.86667\n",
                        "train -  0.99011   |   valid -  0.91111\n",
                        "train -  0.98681   |   valid -  0.85926\n",
                        "train -  0.98763   |   valid -  0.91111\n",
                        "train -  0.98928   |   valid -  0.88148\n",
                        "train -  0.98186   |   valid -  0.85926\n",
                        "train -  0.98846   |   valid -  0.91852\n",
                        "train -  0.99176   |   valid -  0.89630\n",
                        "train -  0.99094   |   valid -  0.88060\n",
                        "train -  0.98847   |   valid -  0.88060\n",
                        "Average accuracy on crossval is 0.88649\n",
                        "Std is 0.02075\n",
                        "\n",
                        "Decision Tree с max_depth=None:\n",
                        "train -  1.00000   |   valid -  0.85926\n",
                        "train -  1.00000   |   valid -  0.91852\n",
                        "train -  1.00000   |   valid -  0.86667\n",
                        "train -  1.00000   |   valid -  0.91111\n",
                        "train -  1.00000   |   valid -  0.88148\n",
                        "train -  1.00000   |   valid -  0.85185\n",
                        "train -  1.00000   |   valid -  0.92593\n",
                        "train -  1.00000   |   valid -  0.88148\n",
                        "train -  1.00000   |   valid -  0.88060\n",
                        "train -  1.00000   |   valid -  0.88060\n",
                        "Average accuracy on crossval is 0.88575\n",
                        "Std is 0.02374\n",
                        "\n",
                        "CPU times: user 358 ms, sys: 0 ns, total: 358 ms\n",
                        "Wall time: 355 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Decision Tree с разными значениями max_depth ===\\n\")\n",
                "\n",
                "max_depth_values = [3, 5, 7, 10, 15, 20, None]\n",
                "tree_scores = {}\n",
                "\n",
                "for depth in max_depth_values:\n",
                "    print(f\"Decision Tree с max_depth={depth}:\")\n",
                "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=21)\n",
                "    score, _ = evaluate_model_cv(tree_model, X_train, y_train)\n",
                "    tree_scores[depth] = score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 210,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Decision Tree с другими параметрами регуляризации ===\n",
                        "\n",
                        "Используем лучшую max_depth=20\n",
                        "Тестируем разные значения min_samples_split:\n",
                        "\n",
                        "Decision Tree с max_depth=20, min_samples_split=2:\n",
                        "train -  0.98846   |   valid -  0.86667\n",
                        "train -  0.99011   |   valid -  0.91111\n",
                        "train -  0.98681   |   valid -  0.85926\n",
                        "train -  0.98763   |   valid -  0.91111\n",
                        "train -  0.98928   |   valid -  0.88148\n",
                        "train -  0.98186   |   valid -  0.85926\n",
                        "train -  0.98846   |   valid -  0.91852\n",
                        "train -  0.99176   |   valid -  0.89630\n",
                        "train -  0.99094   |   valid -  0.88060\n",
                        "train -  0.98847   |   valid -  0.88060\n",
                        "Average accuracy on crossval is 0.88649\n",
                        "Std is 0.02075\n",
                        "\n",
                        "\n",
                        "Decision Tree с max_depth=20, min_samples_split=5:\n",
                        "train -  0.97197   |   valid -  0.85926\n",
                        "train -  0.97197   |   valid -  0.88148\n",
                        "train -  0.97032   |   valid -  0.84444\n",
                        "train -  0.97279   |   valid -  0.89630\n",
                        "train -  0.97032   |   valid -  0.88148\n",
                        "train -  0.96538   |   valid -  0.85926\n",
                        "train -  0.96867   |   valid -  0.91111\n",
                        "train -  0.96867   |   valid -  0.88148\n",
                        "train -  0.97199   |   valid -  0.88060\n",
                        "train -  0.96787   |   valid -  0.87313\n",
                        "Average accuracy on crossval is 0.87685\n",
                        "Std is 0.01820\n",
                        "\n",
                        "\n",
                        "Decision Tree с max_depth=20, min_samples_split=10:\n",
                        "train -  0.94147   |   valid -  0.84444\n",
                        "train -  0.93570   |   valid -  0.83704\n",
                        "train -  0.94477   |   valid -  0.82963\n",
                        "train -  0.94394   |   valid -  0.88148\n",
                        "train -  0.94147   |   valid -  0.85185\n",
                        "train -  0.93899   |   valid -  0.82963\n",
                        "train -  0.92993   |   valid -  0.87407\n",
                        "train -  0.93899   |   valid -  0.85185\n",
                        "train -  0.93987   |   valid -  0.83582\n",
                        "train -  0.92751   |   valid -  0.83582\n",
                        "Average accuracy on crossval is 0.84716\n",
                        "Std is 0.01711\n",
                        "\n",
                        "\n",
                        "Decision Tree с max_depth=20, min_samples_split=20:\n",
                        "train -  0.86397   |   valid -  0.77778\n",
                        "train -  0.85491   |   valid -  0.75556\n",
                        "train -  0.88623   |   valid -  0.77037\n",
                        "train -  0.88623   |   valid -  0.82963\n",
                        "train -  0.86727   |   valid -  0.78519\n",
                        "train -  0.86892   |   valid -  0.77778\n",
                        "train -  0.85161   |   valid -  0.81481\n",
                        "train -  0.86810   |   valid -  0.77037\n",
                        "train -  0.85667   |   valid -  0.75373\n",
                        "train -  0.85502   |   valid -  0.76866\n",
                        "Average accuracy on crossval is 0.78039\n",
                        "Std is 0.02305\n",
                        "\n",
                        "CPU times: user 315 ms, sys: 0 ns, total: 315 ms\n",
                        "Wall time: 310 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Decision Tree с другими параметрами регуляризации ===\\n\")\n",
                "\n",
                "best_depth = max(tree_scores, key=tree_scores.get)\n",
                "print(f\"Используем лучшую max_depth={best_depth}\")\n",
                "\n",
                "print(\"Тестируем разные значения min_samples_split:\")\n",
                "min_samples_split_values = [2, 5, 10, 20]\n",
                "tree_min_split_scores = {}\n",
                "\n",
                "for min_split in min_samples_split_values:\n",
                "    print(f\"\\nDecision Tree с max_depth={best_depth}, min_samples_split={min_split}:\")\n",
                "    tree_model = DecisionTreeClassifier(max_depth=best_depth, min_samples_split=min_split, random_state=21)\n",
                "    score, _ = evaluate_model_cv(tree_model, X_train, y_train)\n",
                "    tree_min_split_scores[min_split] = score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 211,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Сводка результатов Decision Tree ===\n",
                        "\n",
                        "Базовая модель (max_depth=10): 0.72551\n",
                        "\n",
                        "Эксперименты с max depth:\n",
                        "max_depth=3: 0.46140\n",
                        "max_depth=5: 0.54301\n",
                        "max_depth=7: 0.64989\n",
                        "max_depth=10: 0.72551\n",
                        "max_depth=15: 0.85459\n",
                        "max_depth=20: 0.88649\n",
                        "max_depth=None: 0.88575\n",
                        "\n",
                        "Эксперименты с min samples split:\n",
                        "min_samples_split=2: 0.88649\n",
                        "min_samples_split=5: 0.87685\n",
                        "min_samples_split=10: 0.84716\n",
                        "min_samples_split=20: 0.78039\n",
                        "\n",
                        "Лучшие параметры: max_depth=20, min_samples_split=2\n",
                        "Лучший результат: 0.88649\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Сводка результатов Decision Tree ===\\n\")\n",
                "print(f\"Базовая модель (max_depth=10): {tree_baseline_score:.5f}\")\n",
                "print(\"\\nЭксперименты с max depth:\")\n",
                "for depth, score in tree_scores.items():\n",
                "    print(f\"max_depth={depth}: {score:.5f}\")\n",
                "\n",
                "print(\"\\nЭксперименты с min samples split:\")\n",
                "for min_split, score in tree_min_split_scores.items():\n",
                "    print(f\"min_samples_split={min_split}: {score:.5f}\")\n",
                "\n",
                "best_depth = max(tree_scores, key=tree_scores.get)\n",
                "best_min_split = max(tree_min_split_scores, key=tree_min_split_scores.get)\n",
                "tree_best_score = max(max(tree_scores.values()), max(tree_min_split_scores.values()))\n",
                "\n",
                "print(f\"\\nЛучшие параметры: max_depth={best_depth}, min_samples_split={best_min_split}\")\n",
                "print(f\"Лучший результат: {tree_best_score:.5f}\")\n",
                "\n",
                "tree_best = DecisionTreeClassifier(max_depth=best_depth, min_samples_split=best_min_split, random_state=21)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Random forest"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### a. Default regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
                "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
                "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 212,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Random Forest - Базовая модель (n_estimators=50, max_depth=14):\n",
                        "train -  0.96455   |   valid -  0.88148\n",
                        "train -  0.96208   |   valid -  0.91852\n",
                        "train -  0.96785   |   valid -  0.86667\n",
                        "train -  0.96455   |   valid -  0.89630\n",
                        "train -  0.96538   |   valid -  0.91111\n",
                        "train -  0.96538   |   valid -  0.88148\n",
                        "train -  0.97115   |   valid -  0.91852\n",
                        "train -  0.96867   |   valid -  0.85185\n",
                        "train -  0.97364   |   valid -  0.88060\n",
                        "train -  0.97941   |   valid -  0.86567\n",
                        "Average accuracy on crossval is 0.88722\n",
                        "Std is 0.02204\n",
                        "\n",
                        "CPU times: user 903 ms, sys: 0 ns, total: 903 ms\n",
                        "Wall time: 900 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "rf_baseline = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)\n",
                "\n",
                "print(\"Random Forest - Базовая модель (n_estimators=50, max_depth=14):\")\n",
                "rf_baseline_score, rf_baseline_std = evaluate_model_cv(rf_baseline, X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b. Optimizing regularization parameters"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
                "2. As a bonus, play with other regularization parameters trying to find the best combination."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 213,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Random Forest с разными значениями max_depth ===\n",
                        "\n",
                        "Random Forest с n_estimators=50, max_depth=5:\n",
                        "train -  0.62984   |   valid -  0.58519\n",
                        "train -  0.57791   |   valid -  0.55556\n",
                        "train -  0.60181   |   valid -  0.57778\n",
                        "train -  0.59522   |   valid -  0.59259\n",
                        "train -  0.61748   |   valid -  0.57778\n",
                        "train -  0.59687   |   valid -  0.57778\n",
                        "train -  0.61500   |   valid -  0.60741\n",
                        "train -  0.59522   |   valid -  0.57037\n",
                        "train -  0.59967   |   valid -  0.57463\n",
                        "train -  0.60297   |   valid -  0.54478\n",
                        "Average accuracy on crossval is 0.57638\n",
                        "Std is 0.01668\n",
                        "\n",
                        "Random Forest с n_estimators=50, max_depth=10:\n",
                        "train -  0.85408   |   valid -  0.75556\n",
                        "train -  0.85903   |   valid -  0.82963\n",
                        "train -  0.89777   |   valid -  0.80741\n",
                        "train -  0.90107   |   valid -  0.82222\n",
                        "train -  0.88376   |   valid -  0.85185\n",
                        "train -  0.87799   |   valid -  0.75556\n",
                        "train -  0.87222   |   valid -  0.82963\n",
                        "train -  0.86480   |   valid -  0.74074\n",
                        "train -  0.89456   |   valid -  0.82090\n",
                        "train -  0.87644   |   valid -  0.73881\n",
                        "Average accuracy on crossval is 0.79523\n",
                        "Std is 0.04051\n",
                        "\n",
                        "Random Forest с n_estimators=50, max_depth=14:\n",
                        "train -  0.96455   |   valid -  0.88148\n",
                        "train -  0.96208   |   valid -  0.91852\n",
                        "train -  0.96785   |   valid -  0.86667\n",
                        "train -  0.96455   |   valid -  0.89630\n",
                        "train -  0.96538   |   valid -  0.91111\n",
                        "train -  0.96538   |   valid -  0.88148\n",
                        "train -  0.97115   |   valid -  0.91852\n",
                        "train -  0.96867   |   valid -  0.85185\n",
                        "train -  0.97364   |   valid -  0.88060\n",
                        "train -  0.97941   |   valid -  0.86567\n",
                        "Average accuracy on crossval is 0.88722\n",
                        "Std is 0.02204\n",
                        "\n",
                        "Random Forest с n_estimators=50, max_depth=20:\n",
                        "train -  0.99505   |   valid -  0.88889\n",
                        "train -  0.99835   |   valid -  0.94815\n",
                        "train -  0.99670   |   valid -  0.88148\n",
                        "train -  0.99753   |   valid -  0.93333\n",
                        "train -  0.99505   |   valid -  0.91852\n",
                        "train -  0.99670   |   valid -  0.88889\n",
                        "train -  0.99753   |   valid -  0.91852\n",
                        "train -  0.99753   |   valid -  0.91111\n",
                        "train -  0.99753   |   valid -  0.92537\n",
                        "train -  0.99588   |   valid -  0.87313\n",
                        "Average accuracy on crossval is 0.90874\n",
                        "Std is 0.02330\n",
                        "\n",
                        "Random Forest с n_estimators=50, max_depth=None:\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.94815\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.93333\n",
                        "train -  1.00000   |   valid -  0.91111\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.91852\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.93284\n",
                        "train -  0.99918   |   valid -  0.89552\n",
                        "Average accuracy on crossval is 0.91395\n",
                        "Std is 0.01762\n",
                        "\n",
                        "CPU times: user 4.01 s, sys: 0 ns, total: 4.01 s\n",
                        "Wall time: 4 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Random Forest с разными значениями max_depth ===\\n\")\n",
                "\n",
                "rf_max_depth_values = [5, 10, 14, 20, None]\n",
                "rf_depth_scores = {}\n",
                "\n",
                "for depth in rf_max_depth_values:\n",
                "    print(f\"Random Forest с n_estimators=50, max_depth={depth}:\")\n",
                "    rf_model = RandomForestClassifier(n_estimators=50, max_depth=depth, random_state=21)\n",
                "    score, _ = evaluate_model_cv(rf_model, X_train, y_train)\n",
                "    rf_depth_scores[depth] = score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 214,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Random Forest с разными значениями n_estimators ===\n",
                        "\n",
                        "Используем лучшую max_depth=None\n",
                        "\n",
                        "Random Forest с n_estimators=25, max_depth=None:\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.94815\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.93333\n",
                        "train -  0.99918   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.91852\n",
                        "train -  1.00000   |   valid -  0.88889\n",
                        "train -  1.00000   |   valid -  0.92537\n",
                        "train -  0.99918   |   valid -  0.88806\n",
                        "Average accuracy on crossval is 0.91097\n",
                        "Std is 0.01880\n",
                        "\n",
                        "\n",
                        "Random Forest с n_estimators=50, max_depth=None:\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.94815\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.93333\n",
                        "train -  1.00000   |   valid -  0.91111\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.91852\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.93284\n",
                        "train -  0.99918   |   valid -  0.89552\n",
                        "Average accuracy on crossval is 0.91395\n",
                        "Std is 0.01762\n",
                        "\n",
                        "\n",
                        "Random Forest с n_estimators=100, max_depth=None:\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.95556\n",
                        "train -  1.00000   |   valid -  0.91111\n",
                        "train -  1.00000   |   valid -  0.93333\n",
                        "train -  1.00000   |   valid -  0.91111\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.91852\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.91791\n",
                        "train -  1.00000   |   valid -  0.90299\n",
                        "Average accuracy on crossval is 0.91468\n",
                        "Std is 0.01733\n",
                        "\n",
                        "\n",
                        "Random Forest с n_estimators=200, max_depth=None:\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.94815\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.93333\n",
                        "train -  1.00000   |   valid -  0.91111\n",
                        "train -  1.00000   |   valid -  0.88889\n",
                        "train -  1.00000   |   valid -  0.92593\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.92537\n",
                        "train -  1.00000   |   valid -  0.91045\n",
                        "Average accuracy on crossval is 0.91469\n",
                        "Std is 0.01727\n",
                        "\n",
                        "CPU times: user 6.21 s, sys: 0 ns, total: 6.21 s\n",
                        "Wall time: 6.21 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Random Forest с разными значениями n_estimators ===\\n\")\n",
                "\n",
                "best_rf_depth = max(rf_depth_scores, key=rf_depth_scores.get)\n",
                "print(f\"Используем лучшую max_depth={best_rf_depth}\")\n",
                "\n",
                "n_estimators_values = [25, 50, 100, 200]\n",
                "rf_n_est_scores = {}\n",
                "\n",
                "for n_est in n_estimators_values:\n",
                "    print(f\"\\nRandom Forest с n_estimators={n_est}, max_depth={best_rf_depth}:\")\n",
                "    rf_model = RandomForestClassifier(n_estimators=n_est, max_depth=best_rf_depth, random_state=21)\n",
                "    score, _ = evaluate_model_cv(rf_model, X_train, y_train)\n",
                "    rf_n_est_scores[n_est] = score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 215,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Random Forest с другими параметрами регуляризации ===\n",
                        "\n",
                        "Используем лучшие n_estimators=200, max_depth=None\n",
                        "Тестируем разные значения min_samples_split:\n",
                        "\n",
                        "Random Forest с n_estimators=200, max_depth=None, min_samples_split=2:\n",
                        "train -  1.00000   |   valid -  0.89630\n",
                        "train -  1.00000   |   valid -  0.94815\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.93333\n",
                        "train -  1.00000   |   valid -  0.91111\n",
                        "train -  1.00000   |   valid -  0.88889\n",
                        "train -  1.00000   |   valid -  0.92593\n",
                        "train -  1.00000   |   valid -  0.90370\n",
                        "train -  1.00000   |   valid -  0.92537\n",
                        "train -  1.00000   |   valid -  0.91045\n",
                        "Average accuracy on crossval is 0.91469\n",
                        "Std is 0.01727\n",
                        "\n",
                        "\n",
                        "Random Forest с n_estimators=200, max_depth=None, min_samples_split=5:\n",
                        "train -  0.99011   |   valid -  0.89630\n",
                        "train -  0.98928   |   valid -  0.93333\n",
                        "train -  0.98928   |   valid -  0.88148\n",
                        "train -  0.99011   |   valid -  0.92593\n",
                        "train -  0.99258   |   valid -  0.91852\n",
                        "train -  0.99176   |   valid -  0.89630\n",
                        "train -  0.99176   |   valid -  0.91852\n",
                        "train -  0.99176   |   valid -  0.89630\n",
                        "train -  0.99259   |   valid -  0.91791\n",
                        "train -  0.98929   |   valid -  0.86567\n",
                        "Average accuracy on crossval is 0.90502\n",
                        "Std is 0.02025\n",
                        "\n",
                        "\n",
                        "Random Forest с n_estimators=200, max_depth=None, min_samples_split=10:\n",
                        "train -  0.96043   |   valid -  0.88148\n",
                        "train -  0.96290   |   valid -  0.91852\n",
                        "train -  0.95548   |   valid -  0.85926\n",
                        "train -  0.96043   |   valid -  0.89630\n",
                        "train -  0.96290   |   valid -  0.89630\n",
                        "train -  0.95960   |   valid -  0.87407\n",
                        "train -  0.96208   |   valid -  0.90370\n",
                        "train -  0.96373   |   valid -  0.87407\n",
                        "train -  0.96046   |   valid -  0.91045\n",
                        "train -  0.96046   |   valid -  0.85821\n",
                        "Average accuracy on crossval is 0.88724\n",
                        "Std is 0.01989\n",
                        "\n",
                        "CPU times: user 9.34 s, sys: 0 ns, total: 9.34 s\n",
                        "Wall time: 9.33 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "print(\"=== Random Forest с другими параметрами регуляризации ===\\n\")\n",
                "\n",
                "best_rf_n_est = max(rf_n_est_scores, key=rf_n_est_scores.get)\n",
                "print(f\"Используем лучшие n_estimators={best_rf_n_est}, max_depth={best_rf_depth}\")\n",
                "\n",
                "print(\"Тестируем разные значения min_samples_split:\")\n",
                "rf_min_split_values = [2, 5, 10]\n",
                "rf_min_split_scores = {}\n",
                "\n",
                "for min_split in rf_min_split_values:\n",
                "    print(f\"\\nRandom Forest с n_estimators={best_rf_n_est}, max_depth={best_rf_depth}, min_samples_split={min_split}:\")\n",
                "    rf_model = RandomForestClassifier(n_estimators=best_rf_n_est, max_depth=best_rf_depth, \n",
                "                                    min_samples_split=min_split, random_state=21)\n",
                "    score, _ = evaluate_model_cv(rf_model, X_train, y_train)\n",
                "    rf_min_split_scores[min_split] = score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 216,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Сводка результатов Random Forest ===\n",
                        "\n",
                        "Базовая модель (n_estimators=50, max_depth=14): 0.88722\n",
                        "\n",
                        "Эксперименты с max depth:\n",
                        "max_depth=5: 0.57638\n",
                        "max_depth=10: 0.79523\n",
                        "max_depth=14: 0.88722\n",
                        "max_depth=20: 0.90874\n",
                        "max_depth=None: 0.91395\n",
                        "\n",
                        "Эксперименты с n estimators:\n",
                        "n_estimators=25: 0.91097\n",
                        "n_estimators=50: 0.91395\n",
                        "n_estimators=100: 0.91468\n",
                        "n_estimators=200: 0.91469\n",
                        "\n",
                        "Эксперименты с min samples split:\n",
                        "min_samples_split=2: 0.91469\n",
                        "min_samples_split=5: 0.90502\n",
                        "min_samples_split=10: 0.88724\n",
                        "\n",
                        "Лучшие параметры: n_estimators=200, max_depth=None, min_samples_split=2\n",
                        "Лучший результат: 0.91469\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Сводка результатов Random Forest ===\\n\")\n",
                "print(f\"Базовая модель (n_estimators=50, max_depth=14): {rf_baseline_score:.5f}\")\n",
                "\n",
                "print(\"\\nЭксперименты с max depth:\")\n",
                "for depth, score in rf_depth_scores.items():\n",
                "    print(f\"max_depth={depth}: {score:.5f}\")\n",
                "\n",
                "print(\"\\nЭксперименты с n estimators:\")\n",
                "for n_est, score in rf_n_est_scores.items():\n",
                "    print(f\"n_estimators={n_est}: {score:.5f}\")\n",
                "\n",
                "print(\"\\nЭксперименты с min samples split:\")\n",
                "for min_split, score in rf_min_split_scores.items():\n",
                "    print(f\"min_samples_split={min_split}: {score:.5f}\")\n",
                "\n",
                "best_rf_depth = max(rf_depth_scores, key=rf_depth_scores.get)\n",
                "best_rf_n_est = max(rf_n_est_scores, key=rf_n_est_scores.get)\n",
                "best_rf_min_split = max(rf_min_split_scores, key=rf_min_split_scores.get)\n",
                "rf_best_score = max(max(rf_depth_scores.values()), max(rf_n_est_scores.values()), max(rf_min_split_scores.values()))\n",
                "\n",
                "print(f\"\\nЛучшие параметры: n_estimators={best_rf_n_est}, max_depth={best_rf_depth}, min_samples_split={best_rf_min_split}\")\n",
                "print(f\"Лучший результат: {rf_best_score:.5f}\")\n",
                "\n",
                "rf_best = RandomForestClassifier(n_estimators=best_rf_n_est, max_depth=best_rf_depth, \n",
                "                                min_samples_split=best_rf_min_split, random_state=21)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Predictions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. Choose the best model and use it to make predictions for the test dataset.\n",
                "2. Calculate the final accuracy.\n",
                "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
                "4. Save the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 217,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== СРАВНЕНИЕ ФИНАЛЬНЫХ МОДЕЛЕЙ ===\n",
                        "\n",
                        "Logistic Regression (лучшая): 0.62388\n",
                        "SVM (лучшая): 0.75589\n",
                        "Decision Tree (лучшая): 0.88649\n",
                        "Random Forest (лучшая): 0.91469\n",
                        "\n",
                        "Лучшая модель: Random Forest с результатом кросс-валидации: 0.91469\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== СРАВНЕНИЕ ФИНАЛЬНЫХ МОДЕЛЕЙ ===\\n\")\n",
                "print(f\"Logistic Regression (лучшая): {max(logreg_baseline_score, logreg_none_score, logreg_l1_score, logreg_l2_score, logreg_elastic_score):.5f}\")\n",
                "print(f\"SVM (лучшая): {svm_best_score:.5f}\")\n",
                "print(f\"Decision Tree (лучшая): {tree_best_score:.5f}\")\n",
                "print(f\"Random Forest (лучшая): {rf_best_score:.5f}\")\n",
                "\n",
                "model_scores = {\n",
                "    'Logistic Regression': max(logreg_baseline_score, logreg_none_score, logreg_l1_score, logreg_l2_score, logreg_elastic_score),\n",
                "    'SVM': svm_best_score,\n",
                "    'Decision Tree': tree_best_score,\n",
                "    'Random Forest': rf_best_score\n",
                "}\n",
                "\n",
                "best_model_name = max(model_scores, key=model_scores.get)\n",
                "best_score = model_scores[best_model_name]\n",
                "\n",
                "print(f\"\\nЛучшая модель: {best_model_name} с результатом кросс-валидации: {best_score:.5f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 218,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Используем Random Forest с n_estimators=200, max_depth=None, min_samples_split=2\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "RandomForestClassifier(n_estimators=200, random_state=21)"
                        ]
                    },
                    "execution_count": 218,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "best_model = RandomForestClassifier(n_estimators=best_rf_n_est, max_depth=best_rf_depth, \n",
                "                                    min_samples_split=best_rf_min_split, random_state=21)\n",
                "print(f\"Используем Random Forest с n_estimators={best_rf_n_est}, max_depth={best_rf_depth}, min_samples_split={best_rf_min_split}\")\n",
                "best_model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 219,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Финальная точность на тестовом наборе: 0.9378698224852071\n",
                        "\n",
                        "Отчет о классификации:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.95      0.74      0.83        27\n",
                        "           1       0.98      0.95      0.96        55\n",
                        "           2       1.00      0.93      0.97        30\n",
                        "           3       0.92      0.97      0.95        80\n",
                        "           4       0.95      0.86      0.90        21\n",
                        "           5       0.89      0.94      0.92        54\n",
                        "           6       0.93      0.99      0.96        71\n",
                        "\n",
                        "    accuracy                           0.94       338\n",
                        "   macro avg       0.95      0.91      0.93       338\n",
                        "weighted avg       0.94      0.94      0.94       338\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "y_pred = best_model.predict(X_test)\n",
                "test_accuracy = accuracy_score(y_test, y_pred)\n",
                "\n",
                "print(f\"Финальная точность на тестовом наборе: {test_accuracy}\")\n",
                "print(f\"\\nОтчет о классификации:\")\n",
                "print(classification_report(y_test, y_pred))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Classification Report (Отчет о классификации)\n",
                "Здесь видны метрики для каждого дня недели (классы 0-6 = понедельник-воскресенье):\n",
                "\n",
                "- Precision (точность) - из всех дней, которые модель предсказала как \"понедельник\", сколько действительно были понедельниками\n",
                "- Recall (полнота) - из всех реальных понедельников, сколько модель смогла правильно найти"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 220,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== Анализ ошибок по дням недели ===\n",
                        "\n",
                        "Матрица ошибок:\n",
                        "[[20  1  0  1  0  1  4]\n",
                        " [ 0 52  0  2  0  1  0]\n",
                        " [ 0  0 28  2  0  0  0]\n",
                        " [ 1  0  0 78  0  1  0]\n",
                        " [ 0  0  0  0 18  2  1]\n",
                        " [ 0  0  0  2  1 51  0]\n",
                        " [ 0  0  0  0  0  1 70]]\n",
                        "\n",
                        "Понедельник (класс 0): 25.93% ошибок (7/27 ошибок)\n",
                        "Вторник (класс 1): 5.45% ошибок (3/55 ошибок)\n",
                        "Среда (класс 2): 6.67% ошибок (2/30 ошибок)\n",
                        "Четверг (класс 3): 2.50% ошибок (2/80 ошибок)\n",
                        "Пятница (класс 4): 14.29% ошибок (3/21 ошибок)\n",
                        "Суббота (класс 5): 5.56% ошибок (3/54 ошибок)\n",
                        "Воскресенье (класс 6): 1.41% ошибок (1/71 ошибок)\n",
                        "\n",
                        "День недели с наибольшим количеством ошибок: Понедельник (25.93% ошибок)\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== Анализ ошибок по дням недели ===\\n\")\n",
                "\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "print(\"Матрица ошибок:\")\n",
                "print(cm)\n",
                "print()\n",
                "\n",
                "weekdays = ['Понедельник', 'Вторник', 'Среда', 'Четверг', 'Пятница', 'Суббота', 'Воскресенье']\n",
                "error_rates = {}\n",
                "\n",
                "for i, day in enumerate(weekdays):\n",
                "    total_samples = sum(cm[i, :])\n",
                "    correct_predictions = cm[i, i]\n",
                "    error_rate = (total_samples - correct_predictions) / total_samples * 100\n",
                "    error_rates[day] = error_rate\n",
                "    \n",
                "    print(f\"{day} (класс {i}): {error_rate:.2f}% ошибок ({total_samples - correct_predictions}/{total_samples} ошибок)\")\n",
                "\n",
                "worst_day = max(error_rates, key=error_rates.get)\n",
                "worst_error_rate = error_rates[worst_day]\n",
                "\n",
                "print(f\"\\nДень недели с наибольшим количеством ошибок: {worst_day} ({worst_error_rate:.2f}% ошибок)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Confusion Matrix (Матрица ошибок)\n",
                "Показывает, как часто модель путает дни недели:\n",
                "\n",
                "- Диагональ (20, 52, 28, 78, 18, 51, 70) - правильные предсказания\n",
                "- Остальные числа - ошибки\n",
                "\n",
                "Главная проблема: понедельник часто путается с воскресеньем (4 ошибки)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Error Analysis (Анализ ошибок)\n",
                "Понедельник - самый проблемный день (25.93% ошибок):\n",
                "\n",
                "- Модели сложно отличить понедельник от других дней\n",
                "- Возможно, паттерны активности в понедельник менее предсказуемы\n",
                "- Или данных по понедельникам недостаточно (всего 27 образцов)\n",
                "\n",
                "#### Лучше всего модель предсказывает:\n",
                "\n",
                "- Воскресенье (1.41% ошибок)\n",
                "- Четверг (2.50% ошибок)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 221,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Лучшая модель сохранена как: work/src/ex00/model/best_model.joblib\n"
                    ]
                }
            ],
            "source": [
                "model_filename = f'work/src/ex00/model/best_model.joblib'\n",
                "joblib.dump(best_model, model_filename)\n",
                "print(f\"Лучшая модель сохранена как: {model_filename}\")\n",
                "\n",
                "model_info = {\n",
                "    'model_type': best_model_name,\n",
                "    'cv_score': best_score,\n",
                "    'test_accuracy': test_accuracy,\n",
                "    'worst_day': worst_day,\n",
                "    'worst_error_rate': worst_error_rate,\n",
                "    'parameters': str(best_model.get_params())\n",
                "}\n",
                "\n",
                "with open('work/src/ex00/model/model_info.json', 'w') as f:\n",
                "    json.dump(model_info, f, indent=2)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
